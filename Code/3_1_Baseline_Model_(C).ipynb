{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DG-mr64nlHZF"
   },
   "source": [
    "# Baseline Model: Char Level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q2-EJqakEV8z"
   },
   "source": [
    "## Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C8c3NwDGZSdh"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import re\n",
    "import datetime\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk.translate.bleu_score as bleu\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Softmax, RNN, Dense, Embedding, LSTM, Flatten, Activation, GRU, Bidirectional, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping\n",
    "import nltk.translate.bleu_score as bleu\n",
    "import matplotlib.ticker as ticker\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VWejJV0H_sLd",
    "outputId": "e5dbdc17-8306-486e-b69b-34bf7fe58986"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4fnNqtyMCwm9"
   },
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x5bVXVaI9rVp"
   },
   "outputs": [],
   "source": [
    "data_path = '/content/drive/MyDrive/CS2/2.Datasets/'\n",
    "model_path = '/content/drive/MyDrive/CS2/3.Models/3_1_Baseline-Char/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "id": "8IYsmHjRufNN",
    "outputId": "f9230cf5-ad0c-4c65-e806-34ec93d7f9d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101717, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>output_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ofcouse , I love cheap fashion , fast fashion ...</td>\n",
       "      <td>Of course , I love cheap , fast fashion like f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If he want to listen to music that I do n't li...</td>\n",
       "      <td>If he wants to listen to music that I do n't l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This happened because of the cultural differen...</td>\n",
       "      <td>This happened because of the cultural differen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I 'm gon na earn much money to study abroad .</td>\n",
       "      <td>I 'm gon na earn enough money to study abroad .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It is not difficult for me but answer phones a...</td>\n",
       "      <td>It is not difficult for me but answering the p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          input_text                                        output_text\n",
       "0  Ofcouse , I love cheap fashion , fast fashion ...  Of course , I love cheap , fast fashion like f...\n",
       "1  If he want to listen to music that I do n't li...  If he wants to listen to music that I do n't l...\n",
       "2  This happened because of the cultural differen...  This happened because of the cultural differen...\n",
       "3      I 'm gon na earn much money to study abroad .    I 'm gon na earn enough money to study abroad .\n",
       "4  It is not difficult for me but answer phones a...  It is not difficult for me but answering the p..."
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(data_path + 'final_data.csv')\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NCL5fOC6C28O"
   },
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vm9gdQPC-WbF"
   },
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    text = re.sub('<.*>', '', text)\n",
    "    text = re.sub('\\(.*\\)', '', text)\n",
    "    text = re.sub('\\[.*\\]', '', text)\n",
    "    text = re.sub('{.*}', '', text)\n",
    "    text = re.sub(\"[-+@#^/|*(){}$~`<>=_]\",\"\",text)\n",
    "    text = text.replace(\"\\\\\",\"\")\n",
    "    text = re.sub(\"\\[\",\"\",text)\n",
    "    text = re.sub(\"\\]\",\"\",text)\n",
    "    text = re.sub(\"[0-9]\",\"\",text)\n",
    "    return text\n",
    "\n",
    "data['input_text'] = data['input_text'].apply(lambda x: clean(x))\n",
    "data['output_text'] = data['output_text'].apply(lambda x: clean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9QqElB_nKZos"
   },
   "outputs": [],
   "source": [
    "def preprocessing(data):\n",
    "   \n",
    "    data['input_text_length'] = data['input_text'].apply(len)\n",
    "    data['output_text_length'] = data['output_text'].apply(len)\n",
    "\n",
    "    data = data[data['input_text_length'] < 110]\n",
    "    data = data[data['output_text_length'] < 110]\n",
    "\n",
    "    data['output_text_in'] = '\\t ' + data['output_text'].astype(str)\n",
    "    data['output_text_out'] = data['output_text'].astype(str) + ' \\n'\n",
    "\n",
    "    data = data.drop(['input_text_length','output_text_length','output_text'], axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "id": "s4yTTU8cD93w",
    "outputId": "aaefff34-ccc1-4bee-be2f-20f6a42e99f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91188, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>output_text_in</th>\n",
       "      <th>output_text_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ofcouse , I love cheap fashion , fast fashion ...</td>\n",
       "      <td>\\t Of course , I love cheap , fast fashion lik...</td>\n",
       "      <td>Of course , I love cheap , fast fashion like f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If he want to listen to music that I do n't li...</td>\n",
       "      <td>\\t If he wants to listen to music that I do n'...</td>\n",
       "      <td>If he wants to listen to music that I do n't l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I 'm gon na earn much money to study abroad .</td>\n",
       "      <td>\\t I 'm gon na earn enough money to study abro...</td>\n",
       "      <td>I 'm gon na earn enough money to study abroad ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It is not difficult for me but answer phones a...</td>\n",
       "      <td>\\t It is not difficult for me but answering th...</td>\n",
       "      <td>It is not difficult for me but answering the p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The moment came when the world 's would have i...</td>\n",
       "      <td>\\t The moment came when the world would have i...</td>\n",
       "      <td>The moment came when the world would have its ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          input_text  ...                                    output_text_out\n",
       "0  Ofcouse , I love cheap fashion , fast fashion ...  ...  Of course , I love cheap , fast fashion like f...\n",
       "1  If he want to listen to music that I do n't li...  ...  If he wants to listen to music that I do n't l...\n",
       "3      I 'm gon na earn much money to study abroad .  ...  I 'm gon na earn enough money to study abroad ...\n",
       "4  It is not difficult for me but answer phones a...  ...  It is not difficult for me but answering the p...\n",
       "5  The moment came when the world 's would have i...  ...  The moment came when the world would have its ...\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = preprocessing(data)\n",
    "\n",
    "data.iloc[0]['output_text_in'] = str(data.iloc[0]['output_text_in'])+' \\n'\n",
    "data.iloc[0]['output_text_out'] = str(data.iloc[0]['output_text_out'])+' \\n'\n",
    "\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dx2iV7_sC_aJ"
   },
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nwq2jKcGZzt-",
    "outputId": "e39fba3d-6847-4999-d8f4-7ac81e026a54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Train Data: (82069, 3)\n",
      "Shape of Test Data: (9119, 3)\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(data, test_size=0.1, random_state=42)\n",
    "print('Shape of Train Data:', train.shape)\n",
    "print('Shape of Test Data:', test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uiR00g4hDEtl"
   },
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cEqQKioDaFS6",
    "outputId": "ffa8f125-7a79-4216-f9db-411514f3a6b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Vocab Size: 75\n",
      "Output Vocab Size: 68\n"
     ]
    }
   ],
   "source": [
    "tokenizer_i = Tokenizer(filters=\"\",char_level=True,lower=False)\n",
    "tokenizer_o = Tokenizer(filters=\"\",char_level=True,lower=False)\n",
    "\n",
    "tokenizer_i.fit_on_texts(train['input_text'].values)\n",
    "tokenizer_o.fit_on_texts(train['output_text_in'].values)\n",
    "\n",
    "vocab_size_input = len(tokenizer_i.word_index.keys())\n",
    "print('Input Vocab Size:', vocab_size_input)\n",
    "\n",
    "vocab_size_output = len(tokenizer_o.word_index.keys())\n",
    "print('Output Vocab Size:', vocab_size_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BD_URVhfxr_l"
   },
   "outputs": [],
   "source": [
    "input_vocab = tokenizer_i.word_index\n",
    "output_vocab = tokenizer_o.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JfknU1OTDyDe"
   },
   "source": [
    "## Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MLYD6-FR7iZ3"
   },
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, data, tokenizer_i, tokenizer_o, max_len_enc, max_len_dec):\n",
    "        self.encoder_inps = data['input_text'].values\n",
    "        self.decoder_inps = data['output_text_in'].values\n",
    "        self.decoder_outs = data['output_text_out'].values\n",
    "        self.tokenizer_o = tokenizer_o\n",
    "        self.tokenizer_i = tokenizer_i\n",
    "        self.max_len_enc = max_len_enc\n",
    "        self.max_len_dec = max_len_dec\n",
    "\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        self.encoder_seq = self.tokenizer_i.texts_to_sequences([self.encoder_inps[i]]) \n",
    "        self.decoder_inp_seq = self.tokenizer_o.texts_to_sequences([self.decoder_inps[i]])\n",
    "        self.decoder_out_seq = self.tokenizer_o.texts_to_sequences([self.decoder_outs[i]])\n",
    "\n",
    "        self.encoder_seq = pad_sequences(self.encoder_seq, maxlen=self.max_len_enc, dtype='int32', padding='post')\n",
    "        self.decoder_inp_seq = pad_sequences(self.decoder_inp_seq, maxlen=self.max_len_dec, dtype='int32', padding='post')\n",
    "        self.decoder_out_seq = pad_sequences(self.decoder_out_seq, maxlen=self.max_len_dec, dtype='int32', padding='post')\n",
    "        return self.encoder_seq, self.decoder_inp_seq, self.decoder_out_seq\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encoder_inps)\n",
    "\n",
    "    \n",
    "class Dataloder(tf.keras.utils.Sequence):    \n",
    "    def __init__(self, dataset, batch_size=1):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.indexes = np.arange(len(self.dataset.encoder_inps))\n",
    "\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        start = i * self.batch_size\n",
    "        stop = (i + 1) * self.batch_size\n",
    "        data = []\n",
    "        for j in range(start, stop):\n",
    "            data.append(self.dataset[j])\n",
    "\n",
    "        batch = [np.squeeze(np.stack(samples, axis=1), axis=0) for samples in zip(*data)]\n",
    "        return tuple([[batch[0],batch[1]],batch[2]])\n",
    "\n",
    "    def __len__(self): \n",
    "        return len(self.indexes) // self.batch_size\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.random.permutation(self.indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yYS7cpfD7n3S",
    "outputId": "292f0b42-91da-412f-f302-8492746c1c25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataloader: (512, 110) (512, 110) (512, 110)\n",
      "Test Dataloader: (512, 110) (512, 110) (512, 110)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Dataset(train, tokenizer_i, tokenizer_o, 110, 110)\n",
    "test_dataset  = Dataset(test, tokenizer_i, tokenizer_o, 110, 110)\n",
    "\n",
    "train_dataloader = Dataloder(train_dataset, batch_size=512)\n",
    "test_dataloader = Dataloder(test_dataset, batch_size=512)\n",
    "\n",
    "print('Train Dataloader:', train_dataloader[0][0][0].shape, train_dataloader[0][0][1].shape, train_dataloader[0][1].shape)\n",
    "print('Test Dataloader:', test_dataloader[0][0][0].shape, test_dataloader[0][0][1].shape, test_dataloader[0][1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IPfdhIBLQohS"
   },
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aCH8qtWgDFcz"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    '''\n",
    "    Encoder model -- That takes a input sequence and returns encoder-outputs,encoder_final_state_h,encoder_final_state_c\n",
    "    '''\n",
    "    def __init__(self,in_vocab_size,embedding_dim,enc_units,input_length,name='Encoder'):\n",
    "        super().__init__(name=name)\n",
    "        self.in_vocab_size = in_vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.input_length = input_length\n",
    "        self.enc_units = enc_units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.embedding = Embedding(input_dim=self.in_vocab_size, output_dim=self.embedding_dim, input_length=self.input_length, mask_zero=True, name=\"Encoder_Embedding\")\n",
    "        self.lstm = LSTM(self.enc_units, return_state=True, return_sequences=True, name=\"Encoder_LSTM\")\n",
    "        \n",
    "    def call(self,input_sentences,training=True):\n",
    "        input_embed = self.embedding(input_sentences)\n",
    "        encoder_output, encoder_state_h, encoder_state_c = self.lstm(input_embed)\n",
    "        return encoder_output, encoder_state_h, encoder_state_c\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------\n",
    "class Decoder(tf.keras.Model):\n",
    "    '''\n",
    "    Decoder model -- That takes a input sequence and returns output sequence\n",
    "    '''\n",
    "    def __init__(self,out_vocab_size,embedding_dim,dec_units,input_length,name='Decoder'):\n",
    "        super().__init__(name=name)\n",
    "        self.out_vocab_size = out_vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.dec_units = dec_units\n",
    "        self.input_length = input_length\n",
    "     \n",
    "    def build(self, input_shape):\n",
    "        self.embedding = Embedding(input_dim=self.out_vocab_size, output_dim=self.embedding_dim, input_length=self.input_length, mask_zero=True, name=\"Decoder_Embedding\")\n",
    "        self.lstm = LSTM(self.dec_units, return_sequences=True, return_state=True, name=\"Decoder_LSTM\")\n",
    "        \n",
    "    def call(self,target_sentences,initial_states):\n",
    "        target_embedd = self.embedding(target_sentences)\n",
    "        decoder_output, decoder_final_state_h, decoder_final_state_c = self.lstm(target_embedd, initial_state=initial_states)\n",
    "        return decoder_output, decoder_final_state_h, decoder_final_state_c\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------\n",
    "class Encoder_Decoder(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, encoder_inputs_length, decoder_inputs_length, in_vocab_size, out_vocab_size, embedding_dim, enc_units, dec_units, name='Encoder-Decoder'):\n",
    "        super().__init__(name=name)\n",
    "        self.encoder = Encoder(in_vocab_size=in_vocab_size+1, embedding_dim=embedding_dim, enc_units=enc_units, input_length=encoder_inputs_length)\n",
    "        self.decoder = Decoder(out_vocab_size=out_vocab_size+1, embedding_dim=embedding_dim, dec_units=dec_units, input_length=decoder_inputs_length)\n",
    "        self.dense   = Dense(out_vocab_size, activation='softmax', name='Dense')\n",
    "    \n",
    "    def call(self, data):\n",
    "        input, output = data[0], data[1]\n",
    "\n",
    "        encoder_output, encoder_h, encoder_c = self.encoder(input)\n",
    "        decoder_output, decoder_h, decoder_c = self.decoder(output, [encoder_h, encoder_c])\n",
    "        output                               = self.dense(decoder_output)\n",
    "        return output\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------\n",
    "def build_model_lstm(name):\n",
    "  model = Encoder_Decoder(encoder_inputs_length=110, decoder_inputs_length=110, in_vocab_size=vocab_size_input, out_vocab_size=vocab_size_output,embedding_dim=300, enc_units=100, dec_units=100, name=name)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1NDBTnGeMm99"
   },
   "outputs": [],
   "source": [
    "def train_model(model, model_name):\n",
    "\n",
    "    es = EarlyStopping(patience=3, verbose=1, min_delta=0.001, monitor='val_loss', mode='min', restore_best_weights=True)\n",
    "    lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.99, patience=100)\n",
    "\n",
    "    train_steps = train.shape[0]//512\n",
    "    test_steps = test.shape[0]//512\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(), loss='sparse_categorical_crossentropy')\n",
    "\n",
    "    with tf.device('/device:GPU:0'):\n",
    "        model.fit(train_dataloader, steps_per_epoch=train_steps, epochs=20, validation_data=test_dataloader, validation_steps=test_steps, callbacks=[es,lr])\n",
    "\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "11PwkigioLFN"
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2pIqWNBArtwL",
    "outputId": "62f87864-d2a4-403d-8d36-7f71eb00d711"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "160/160 [==============================] - 83s 461ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/20\n",
      "160/160 [==============================] - 70s 441ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/20\n",
      "160/160 [==============================] - 72s 451ms/step - loss: nan - val_loss: nan\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00003: early stopping\n",
      "Model: \"LSTM_Encoder-Decoder_Scratch\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Encoder (Encoder)            multiple                  183200    \n",
      "_________________________________________________________________\n",
      "Decoder (Decoder)            multiple                  181100    \n",
      "_________________________________________________________________\n",
      "Dense (Dense)                multiple                  6868      \n",
      "=================================================================\n",
      "Total params: 371,168\n",
      "Trainable params: 371,168\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model_lstm(name='LSTM_Encoder-Decoder_Scratch')\n",
    "train_model(model, 'LSTM_Encoder-Decoder_Scratch')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "3_1_Baseline_Model_(C).ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
