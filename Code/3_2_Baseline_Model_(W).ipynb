{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DG-mr64nlHZF"
   },
   "source": [
    "# Baseline Model: Word Level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q2-EJqakEV8z"
   },
   "source": [
    "## Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C8c3NwDGZSdh"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import re\n",
    "import datetime\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk.translate.bleu_score as bleu\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Softmax, RNN, Dense, Embedding, LSTM, Flatten, Activation, GRU, Bidirectional, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping\n",
    "import nltk.translate.bleu_score as bleu\n",
    "import matplotlib.ticker as ticker\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VWejJV0H_sLd",
    "outputId": "f2930309-2d4d-40d2-f169-9f814ecac145"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4fnNqtyMCwm9"
   },
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JcmMnfZEzXKA"
   },
   "outputs": [],
   "source": [
    "data_path = '/content/drive/MyDrive/CS2/2.Datasets/'\n",
    "model_path = '/content/drive/MyDrive/CS2/3.Models/3_2_Baseline-Word/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "id": "8IYsmHjRufNN",
    "outputId": "9e651692-e718-475e-e18b-f499f33c583d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101717, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>output_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ofcouse , I love cheap fashion , fast fashion ...</td>\n",
       "      <td>Of course , I love cheap , fast fashion like f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If he want to listen to music that I do n't li...</td>\n",
       "      <td>If he wants to listen to music that I do n't l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This happened because of the cultural differen...</td>\n",
       "      <td>This happened because of the cultural differen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I 'm gon na earn much money to study abroad .</td>\n",
       "      <td>I 'm gon na earn enough money to study abroad .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It is not difficult for me but answer phones a...</td>\n",
       "      <td>It is not difficult for me but answering the p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          input_text                                        output_text\n",
       "0  Ofcouse , I love cheap fashion , fast fashion ...  Of course , I love cheap , fast fashion like f...\n",
       "1  If he want to listen to music that I do n't li...  If he wants to listen to music that I do n't l...\n",
       "2  This happened because of the cultural differen...  This happened because of the cultural differen...\n",
       "3      I 'm gon na earn much money to study abroad .    I 'm gon na earn enough money to study abroad .\n",
       "4  It is not difficult for me but answer phones a...  It is not difficult for me but answering the p..."
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(data_path + 'final_data.csv')\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NCL5fOC6C28O"
   },
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Efo7NtfGy4Qj"
   },
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    text = re.sub('<.*>', '', text)\n",
    "    text = re.sub('\\(.*\\)', '', text)\n",
    "    text = re.sub('\\[.*\\]', '', text)\n",
    "    text = re.sub('{.*}', '', text)\n",
    "    text = re.sub(\"[-+@#^/|*(){}$~`<>=_]\",\"\",text)\n",
    "    text = text.replace(\"\\\\\",\"\")\n",
    "    text = re.sub(\"\\[\",\"\",text)\n",
    "    text = re.sub(\"\\]\",\"\",text)\n",
    "    text = re.sub(\"[0-9]\",\"\",text)\n",
    "    return text\n",
    "\n",
    "data['input_text'] = data['input_text'].apply(lambda x: clean(x))\n",
    "data['output_text'] = data['output_text'].apply(lambda x: clean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9QqElB_nKZos"
   },
   "outputs": [],
   "source": [
    "def preprocessing(data):\n",
    "   \n",
    "    data['input_text_length'] = data['input_text'].str.split().apply(len)\n",
    "    data['output_text_length'] = data['output_text'].str.split().apply(len)\n",
    "\n",
    "    data = data[data['input_text_length'] < 25]\n",
    "    data = data[data['output_text_length'] < 25]\n",
    "\n",
    "    data['output_text_in'] = '<start> ' + data['output_text'].astype(str)\n",
    "    data['output_text_out'] = data['output_text'].astype(str) + ' <end>'\n",
    "\n",
    "    data = data.drop(['input_text_length','output_text_length','output_text'], axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "id": "s4yTTU8cD93w",
    "outputId": "984b92f2-61af-4b96-af2d-17f58d23566a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93503, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>output_text_in</th>\n",
       "      <th>output_text_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ofcouse , I love cheap fashion , fast fashion ...</td>\n",
       "      <td>&lt;start&gt; Of course , I love cheap , fast fashio...</td>\n",
       "      <td>Of course , I love cheap , fast fashion like f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If he want to listen to music that I do n't li...</td>\n",
       "      <td>&lt;start&gt; If he wants to listen to music that I ...</td>\n",
       "      <td>If he wants to listen to music that I do n't l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This happened because of the cultural differen...</td>\n",
       "      <td>&lt;start&gt; This happened because of the cultural ...</td>\n",
       "      <td>This happened because of the cultural differen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I 'm gon na earn much money to study abroad .</td>\n",
       "      <td>&lt;start&gt; I 'm gon na earn enough money to study...</td>\n",
       "      <td>I 'm gon na earn enough money to study abroad ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It is not difficult for me but answer phones a...</td>\n",
       "      <td>&lt;start&gt; It is not difficult for me but answeri...</td>\n",
       "      <td>It is not difficult for me but answering the p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          input_text  ...                                    output_text_out\n",
       "0  Ofcouse , I love cheap fashion , fast fashion ...  ...  Of course , I love cheap , fast fashion like f...\n",
       "1  If he want to listen to music that I do n't li...  ...  If he wants to listen to music that I do n't l...\n",
       "2  This happened because of the cultural differen...  ...  This happened because of the cultural differen...\n",
       "3      I 'm gon na earn much money to study abroad .  ...  I 'm gon na earn enough money to study abroad ...\n",
       "4  It is not difficult for me but answer phones a...  ...  It is not difficult for me but answering the p...\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = preprocessing(data)\n",
    "\n",
    "data.iloc[0]['output_text_in'] = str(data.iloc[0]['output_text_in'])+' <end>'\n",
    "data.iloc[0]['output_text_out'] = str(data.iloc[0]['output_text_out'])+' <end>'\n",
    "\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dx2iV7_sC_aJ"
   },
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nwq2jKcGZzt-",
    "outputId": "4cc95ef5-28bb-4980-b5ba-cad700db45c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Train Data: (84152, 3)\n",
      "Shape of Test Data: (9351, 3)\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(data, test_size=0.1, random_state=42)\n",
    "print('Shape of Train Data:', train.shape)\n",
    "print('Shape of Test Data:', test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uiR00g4hDEtl"
   },
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cEqQKioDaFS6",
    "outputId": "8e1a853d-8b54-400a-8b54-24602e7b63a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Vocab Size: 35510\n",
      "Output Vocab Size: 29350\n"
     ]
    }
   ],
   "source": [
    "tokenizer_i = Tokenizer(filters=\"\", char_level=False, lower=False)\n",
    "tokenizer_o = Tokenizer(filters=\"\", char_level=False, lower=False)\n",
    "\n",
    "tokenizer_i.fit_on_texts(train['input_text'].values)\n",
    "tokenizer_o.fit_on_texts(train['output_text_in'].values)\n",
    "\n",
    "vocab_size_input = len(tokenizer_i.word_index.keys())\n",
    "print('Input Vocab Size:', vocab_size_input)\n",
    "\n",
    "vocab_size_output = len(tokenizer_o.word_index.keys())\n",
    "print('Output Vocab Size:', vocab_size_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BD_URVhfxr_l"
   },
   "outputs": [],
   "source": [
    "input_vocab = tokenizer_i.word_index\n",
    "output_vocab = tokenizer_o.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JfknU1OTDyDe"
   },
   "source": [
    "## Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MLYD6-FR7iZ3"
   },
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, data, tokenizer_i, tokenizer_o, max_len_enc, max_len_dec):\n",
    "        self.encoder_inps = data['input_text'].values\n",
    "        self.decoder_inps = data['output_text_in'].values\n",
    "        self.decoder_outs = data['output_text_out'].values\n",
    "        self.tokenizer_o = tokenizer_o\n",
    "        self.tokenizer_i = tokenizer_i\n",
    "        self.max_len_enc = max_len_enc\n",
    "        self.max_len_dec = max_len_dec\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        self.encoder_seq = self.tokenizer_i.texts_to_sequences([self.encoder_inps[i]]) \n",
    "        self.decoder_inp_seq = self.tokenizer_o.texts_to_sequences([self.decoder_inps[i]])\n",
    "        self.decoder_out_seq = self.tokenizer_o.texts_to_sequences([self.decoder_outs[i]])\n",
    "\n",
    "        self.encoder_seq = pad_sequences(self.encoder_seq, maxlen=self.max_len_enc, dtype='int32', padding='post')\n",
    "        self.decoder_inp_seq = pad_sequences(self.decoder_inp_seq, maxlen=self.max_len_dec, dtype='int32', padding='post')\n",
    "        self.decoder_out_seq = pad_sequences(self.decoder_out_seq, maxlen=self.max_len_dec, dtype='int32', padding='post')\n",
    "        return self.encoder_seq, self.decoder_inp_seq, self.decoder_out_seq\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encoder_inps)\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------\n",
    "class Dataloder(tf.keras.utils.Sequence):    \n",
    "    def __init__(self, dataset, batch_size=1):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.indexes = np.arange(len(self.dataset.encoder_inps))\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        start = i * self.batch_size\n",
    "        stop = (i + 1) * self.batch_size\n",
    "        data = []\n",
    "        for j in range(start, stop):\n",
    "            data.append(self.dataset[j])\n",
    "\n",
    "        batch = [np.squeeze(np.stack(samples, axis=1), axis=0) for samples in zip(*data)]\n",
    "        return tuple([[batch[0],batch[1]],batch[2]])\n",
    "\n",
    "    def __len__(self): \n",
    "        return len(self.indexes) // self.batch_size\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.random.permutation(self.indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yYS7cpfD7n3S",
    "outputId": "eb8a18c1-a673-4ee2-9773-b8a68bb3445d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataloader: (512, 25) (512, 25) (512, 25)\n",
      "Test Dataloader: (512, 25) (512, 25) (512, 25)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Dataset(train, tokenizer_i, tokenizer_o, 25, 25)\n",
    "test_dataset  = Dataset(test, tokenizer_i, tokenizer_o, 25, 25)\n",
    "\n",
    "train_dataloader = Dataloder(train_dataset, batch_size=512)\n",
    "test_dataloader = Dataloder(test_dataset, batch_size=512)\n",
    "\n",
    "print('Train Dataloader:', train_dataloader[0][0][0].shape, train_dataloader[0][0][1].shape, train_dataloader[0][1].shape)\n",
    "print('Test Dataloader:', test_dataloader[0][0][0].shape, test_dataloader[0][0][1].shape, test_dataloader[0][1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ub9taIsltuBO"
   },
   "source": [
    "## Creating Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y_TYjDGCAVgz"
   },
   "source": [
    "### Glove Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z6T2cGZIxKj9",
    "outputId": "aa1514f6-27a8-402b-f726-a832b1759d5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-08-12 07:00:59--  http://nlp.stanford.edu/data/glove.6B.zip\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
      "--2021-08-12 07:00:59--  https://nlp.stanford.edu/data/glove.6B.zip\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
      "--2021-08-12 07:00:59--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
      "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
      "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 862182613 (822M) [application/zip]\n",
      "Saving to: ‘glove.6B.zip’\n",
      "\n",
      "glove.6B.zip        100%[===================>] 822.24M  5.07MB/s    in 2m 41s  \n",
      "\n",
      "2021-08-12 07:03:40 (5.12 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
      "\n",
      "Archive:  glove.6B.zip\n",
      "  inflating: glove.6B.50d.txt        \n",
      "  inflating: glove.6B.100d.txt       \n",
      "  inflating: glove.6B.200d.txt       \n",
      "  inflating: glove.6B.300d.txt       \n"
     ]
    }
   ],
   "source": [
    "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "!unzip glove*.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I43aqTLAxHmA",
    "outputId": "e2efb7b6-b4cb-443c-974b-6fc930c2a044"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded word vectors = 400000\n",
      "Shape of Encoder Embedding Matrix = (35511, 300)\n",
      "Shape of Decoder Embedding Matrix = (29351, 300)\n"
     ]
    }
   ],
   "source": [
    "# load the whole embedding into memory\n",
    "embeddings_index = dict()\n",
    "f = open('glove.6B.300d.txt') \n",
    "for line in f:\n",
    "\tvalues = line.split()\n",
    "\tword = values[0]\n",
    "\tcoefs = np.asarray(values[1:], dtype='float32')\n",
    "\tembeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded word vectors =', len(embeddings_index))\n",
    "\n",
    "# create a weight matrix for words in training docs\n",
    "encoder_embedding_matrix_glove = np.zeros((len(input_vocab)+1, 300))\n",
    "for word, i in input_vocab.items():\n",
    "\tembedding_vector = embeddings_index.get(word)\n",
    "\tif embedding_vector is not None:\n",
    "\t\tencoder_embedding_matrix_glove[i] = embedding_vector\n",
    "print('Shape of Encoder Embedding Matrix =', encoder_embedding_matrix_glove.shape)\n",
    "\n",
    "# create a weight matrix for words in training docs\n",
    "decoder_embedding_matrix_glove = np.zeros((len(output_vocab)+1, 300))\n",
    "for word, i in output_vocab.items():\n",
    "\tembedding_vector = embeddings_index.get(word)\n",
    "\tif embedding_vector is not None:\n",
    "\t\tdecoder_embedding_matrix_glove[i] = embedding_vector\n",
    "print('Shape of Decoder Embedding Matrix =', decoder_embedding_matrix_glove.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J1r61_f6AdxW"
   },
   "source": [
    "### Fasttext Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E7sirPKkAdNZ",
    "outputId": "35f7e110-da35-4dde-bd4e-833d29e4c189"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-08-12 07:22:05--  https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\n",
      "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.74.142, 172.67.9.4, 104.22.75.142, ...\n",
      "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 681808098 (650M) [application/zip]\n",
      "Saving to: ‘wiki-news-300d-1M.vec.zip’\n",
      "\n",
      "wiki-news-300d-1M.v 100%[===================>] 650.22M  33.4MB/s    in 20s     \n",
      "\n",
      "2021-08-12 07:22:26 (31.9 MB/s) - ‘wiki-news-300d-1M.vec.zip’ saved [681808098/681808098]\n",
      "\n",
      "Archive:  wiki-news-300d-1M.vec.zip\n",
      "  inflating: wiki-news-300d-1M.vec   \n"
     ]
    }
   ],
   "source": [
    "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\n",
    "!unzip wiki-news-300d-1M.vec.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pZSIpksCAi38",
    "outputId": "f539e826-dd36-43ca-860d-4130ebf25d9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded word vectors = 999995\n",
      "Shape of Encoder Embedding Matrix = (35511, 300)\n",
      "Shape of Decoder Embedding Matrix = (29351, 300)\n"
     ]
    }
   ],
   "source": [
    "# load the whole embedding into memory\n",
    "embeddings_index = dict()\n",
    "f = open('wiki-news-300d-1M.vec') \n",
    "for line in f:\n",
    "\tvalues = line.split()\n",
    "\tword = values[0]\n",
    "\tcoefs = np.asarray(values[1:], dtype='float32')\n",
    "\tembeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded word vectors =', len(embeddings_index))\n",
    "\n",
    "# create a weight matrix for words in training docs\n",
    "encoder_embedding_matrix_fast = np.zeros((len(input_vocab)+1, 300))\n",
    "for word, i in input_vocab.items():\n",
    "\tembedding_vector = embeddings_index.get(word)\n",
    "\tif embedding_vector is not None:\n",
    "\t\tencoder_embedding_matrix_fast[i] = embedding_vector\n",
    "print('Shape of Encoder Embedding Matrix =', encoder_embedding_matrix_fast.shape)\n",
    "\n",
    "# create a weight matrix for words in training docs\n",
    "decoder_embedding_matrix_fast = np.zeros((len(output_vocab)+1, 300))\n",
    "for word, i in output_vocab.items():\n",
    "\tembedding_vector = embeddings_index.get(word)\n",
    "\tif embedding_vector is not None:\n",
    "\t\tdecoder_embedding_matrix_fast[i] = embedding_vector\n",
    "print('Shape of Decoder Embedding Matrix =', decoder_embedding_matrix_fast.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IPfdhIBLQohS"
   },
   "source": [
    "# LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aCH8qtWgDFcz"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    '''\n",
    "    Encoder model -- That takes a input sequence and returns encoder-outputs,encoder_final_state_h,encoder_final_state_c\n",
    "    '''\n",
    "    def __init__(self,in_vocab_size,embedding_dim,enc_units,input_length,embed,name='Encoder'):\n",
    "        super().__init__(name=name)\n",
    "        self.in_vocab_size = in_vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.input_length = input_length\n",
    "        self.enc_units = enc_units\n",
    "        self.embed = embed\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if self.embed == 'scratch':\n",
    "            self.embedding = Embedding(input_dim=self.in_vocab_size, output_dim=self.embedding_dim, input_length=self.input_length, mask_zero=True, name=\"Encoder_Embedding\")\n",
    "        elif self.embed == 'glove':\n",
    "            self.embedding = Embedding(input_dim=self.in_vocab_size, output_dim=self.embedding_dim, input_length=self.input_length, mask_zero=True, weights=[encoder_embedding_matrix_glove], trainable=False, name=\"Encoder_Embedding\")\n",
    "        elif self.embed == 'fast':\n",
    "            self.embedding = Embedding(input_dim=self.in_vocab_size, output_dim=self.embedding_dim, input_length=self.input_length, mask_zero=True, weights=[encoder_embedding_matrix_fast], trainable=False, name=\"Encoder_Embedding\")\n",
    "\n",
    "        self.lstm = LSTM(self.enc_units, return_state=True, return_sequences=True, name=\"Encoder_LSTM\")\n",
    "        \n",
    "    def call(self,input_sentences,training=True):\n",
    "        input_embed = self.embedding(input_sentences)\n",
    "        encoder_output, encoder_state_h, encoder_state_c = self.lstm(input_embed)\n",
    "        return encoder_output, encoder_state_h, encoder_state_c\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------\n",
    "class Decoder(tf.keras.Model):\n",
    "    '''\n",
    "    Decoder model -- That takes a input sequence and returns output sequence\n",
    "    '''\n",
    "    def __init__(self,out_vocab_size,embedding_dim,dec_units,input_length,embed,name='Decoder'):\n",
    "        super().__init__(name=name)\n",
    "        self.out_vocab_size = out_vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.dec_units = dec_units\n",
    "        self.input_length = input_length\n",
    "        self.embed = embed\n",
    "     \n",
    "    def build(self, input_shape):\n",
    "        if self.embed == 'scratch':\n",
    "            self.embedding = Embedding(input_dim=self.out_vocab_size, output_dim=self.embedding_dim, input_length=self.input_length, mask_zero=True, name=\"Decoder_Embedding\")\n",
    "        elif self.embed == 'glove':\n",
    "            self.embedding = Embedding(input_dim=self.out_vocab_size, output_dim=self.embedding_dim, input_length=self.input_length, mask_zero=True, weights=[decoder_embedding_matrix_glove], trainable=False, name=\"Decoder_Embedding\")\n",
    "        elif self.embed == 'fast':\n",
    "            self.embedding = Embedding(input_dim=self.out_vocab_size, output_dim=self.embedding_dim, input_length=self.input_length, mask_zero=True, weights=[decoder_embedding_matrix_fast], trainable=False, name=\"Decoder_Embedding\")\n",
    "\n",
    "        self.lstm = LSTM(self.dec_units, return_sequences=True, return_state=True, name=\"Decoder_LSTM\")\n",
    "        \n",
    "    def call(self,target_sentences,initial_states):\n",
    "        target_embedd = self.embedding(target_sentences)\n",
    "        decoder_output, decoder_final_state_h, decoder_final_state_c = self.lstm(target_embedd, initial_state=initial_states)\n",
    "        return decoder_output, decoder_final_state_h, decoder_final_state_c\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------\n",
    "class Encoder_Decoder(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, encoder_inputs_length, decoder_inputs_length, in_vocab_size, out_vocab_size, embedding_dim, enc_units, dec_units, embed, name='Encoder-Decoder'):\n",
    "        super().__init__(name=name)\n",
    "        self.encoder = Encoder(in_vocab_size=in_vocab_size+1, embedding_dim=embedding_dim, enc_units=enc_units, input_length=encoder_inputs_length, embed=embed)\n",
    "        self.decoder = Decoder(out_vocab_size=out_vocab_size+1, embedding_dim=embedding_dim, dec_units=dec_units, input_length=decoder_inputs_length, embed=embed)\n",
    "        self.dense   = Dense(out_vocab_size, activation='softmax', name='Dense')\n",
    "    \n",
    "    def call(self, data):\n",
    "        input, output = data[0], data[1]\n",
    "\n",
    "        encoder_output, encoder_h, encoder_c = self.encoder(input)\n",
    "        decoder_output, decoder_h, decoder_c = self.decoder(output, [encoder_h, encoder_c])\n",
    "        output                               = self.dense(decoder_output)\n",
    "        return output\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------\n",
    "def build_model_lstm(embed, name):\n",
    "  model = Encoder_Decoder(encoder_inputs_length=25, decoder_inputs_length=25, in_vocab_size=vocab_size_input, out_vocab_size=vocab_size_output,embedding_dim=300, enc_units=100, dec_units=100, embed=embed, name=name)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1NDBTnGeMm99"
   },
   "outputs": [],
   "source": [
    "def train_model(model, model_name):\n",
    "\n",
    "    es = EarlyStopping(patience=3, verbose=1, min_delta=0.001, monitor='val_loss', mode='min', restore_best_weights=True)\n",
    "    \n",
    "    train_steps = train.shape[0]//512\n",
    "    test_steps = test.shape[0]//512\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(), loss='sparse_categorical_crossentropy')\n",
    "\n",
    "    with tf.device('/device:GPU:0'):\n",
    "        model.fit(train_dataloader, steps_per_epoch=train_steps, epochs=20, validation_data=test_dataloader, validation_steps=test_steps, callbacks=[es])\n",
    "\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ekmsxBkyIH6j"
   },
   "outputs": [],
   "source": [
    "def predict(input_sentence, model):\n",
    " \n",
    "  DECODER_SEQ_LEN = 25\n",
    "  predict_word_idx = np.zeros((1, 1))\n",
    "  predict_word_idx[0,0] = 1\n",
    "  predicted_sentence = ''\n",
    "\n",
    "  input_sequence=tokenizer_i.texts_to_sequences([input_sentence])\n",
    "  inputs=pad_sequences(input_sequence,maxlen=25,padding='post')\n",
    "  inputs=tf.convert_to_tensor(inputs)\n",
    "\n",
    "  enc_output, enc_state_h, enc_state_c = model.layers[0](inputs)\n",
    "  states_values = [enc_state_h, enc_state_c]\n",
    "\n",
    "  for i in range(DECODER_SEQ_LEN):\n",
    "        predict_emb = model.layers[1].embedding(predict_word_idx)\n",
    "        [dec_output, dec_state_h, dec_state_c] = model.layers[1].lstm(predict_emb, initial_state=states_values)\n",
    "        dec_output = model.layers[2](dec_output)\n",
    "        states_values = [dec_state_h, dec_state_c]\n",
    "\n",
    "        predict_word_idx = np.reshape(np.argmax(dec_output), (1, 1))\n",
    "        predicted_sentence += ' ' + tokenizer_o.index_word[int(predict_word_idx)]\n",
    "\n",
    "        if tokenizer_o.word_index['<end>'] == predict_word_idx:\n",
    "            return predicted_sentence\n",
    "   \n",
    "  return predicted_sentence\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------\n",
    "def predict_result(data, model):\n",
    "    for i in range(len(data[:3])):\n",
    "        print(\"Input Text:\", data['input_text'].iloc[i])\n",
    "        print(\"Output Text:\", ' '.join(data['output_text_out'].iloc[i].split()[:-1]))\n",
    "        print(\"Predicted Text:\", ' '.join(predict(data['input_text'].iloc[i], model).split()[:-1]))\n",
    "        print('='*100)\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------\n",
    "def get_BLEU(train, test, model):\n",
    "    total_bleu=0\n",
    "    input_range = 100\n",
    "    for i in range(0,input_range):\n",
    "        output_sentence = ' '.join(train['output_text_out'].iloc[i].split()[:-1])\n",
    "        predicted_sentence = ' '.join(predict(train['input_text'].iloc[i], model).split()[:-1])\n",
    "        output_sentence = [output_sentence.split()]\n",
    "        predicted_sentence = predicted_sentence.split()\n",
    "        bleu_score = bleu.sentence_bleu(output_sentence, predicted_sentence)\n",
    "        total_bleu += bleu_score\n",
    "    train_avg_bleu = total_bleu/input_range\n",
    "\n",
    "    total_bleu=0\n",
    "    input_range = 100\n",
    "    for i in range(0,input_range):\n",
    "        output_sentence = ' '.join(test['output_text_out'].iloc[i].split()[:-1])\n",
    "        predicted_sentence = ' '.join(predict(test['input_text'].iloc[i], model).split()[:-1])\n",
    "        output_sentence = [output_sentence.split()]\n",
    "        predicted_sentence = predicted_sentence.split()\n",
    "        bleu_score = bleu.sentence_bleu(output_sentence, predicted_sentence)\n",
    "        total_bleu += bleu_score\n",
    "    test_avg_bleu = total_bleu/input_range\n",
    "\n",
    "    print('='*50)\n",
    "    print('Avg. Train BLEU Score:', train_avg_bleu)\n",
    "    print('Avg. Test BLEU Score:', test_avg_bleu)\n",
    "    print('='*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jRo1CiXDUSMS"
   },
   "source": [
    "## Encoder-Decoder: Scratch Embed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "11PwkigioLFN"
   },
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2pIqWNBArtwL",
    "outputId": "99c6b843-4788-434e-cf3a-206e18f85cea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "164/164 [==============================] - 79s 447ms/step - loss: 3.5283 - val_loss: 3.0048\n",
      "Epoch 2/20\n",
      "164/164 [==============================] - 70s 428ms/step - loss: 2.9811 - val_loss: 2.7867\n",
      "Epoch 3/20\n",
      "164/164 [==============================] - 70s 427ms/step - loss: 2.7944 - val_loss: 2.6377\n",
      "Epoch 4/20\n",
      "164/164 [==============================] - 70s 430ms/step - loss: 2.6477 - val_loss: 2.5103\n",
      "Epoch 5/20\n",
      "164/164 [==============================] - 69s 423ms/step - loss: 2.4967 - val_loss: 2.3686\n",
      "Epoch 6/20\n",
      "164/164 [==============================] - 70s 429ms/step - loss: 2.3614 - val_loss: 2.2613\n",
      "Epoch 7/20\n",
      "164/164 [==============================] - 70s 424ms/step - loss: 2.2460 - val_loss: 2.1697\n",
      "Epoch 8/20\n",
      "164/164 [==============================] - 69s 419ms/step - loss: 2.1450 - val_loss: 2.0889\n",
      "Epoch 9/20\n",
      "164/164 [==============================] - 70s 425ms/step - loss: 2.0484 - val_loss: 2.0144\n",
      "Epoch 10/20\n",
      "164/164 [==============================] - 69s 422ms/step - loss: 1.9591 - val_loss: 1.9500\n",
      "Epoch 11/20\n",
      "164/164 [==============================] - 69s 421ms/step - loss: 1.8762 - val_loss: 1.8944\n",
      "Epoch 12/20\n",
      "164/164 [==============================] - 69s 421ms/step - loss: 1.8004 - val_loss: 1.8471\n",
      "Epoch 13/20\n",
      "164/164 [==============================] - 70s 424ms/step - loss: 1.7311 - val_loss: 1.8098\n",
      "Epoch 14/20\n",
      "164/164 [==============================] - 69s 420ms/step - loss: 1.6680 - val_loss: 1.7778\n",
      "Epoch 15/20\n",
      "164/164 [==============================] - 70s 426ms/step - loss: 1.6103 - val_loss: 1.7497\n",
      "Epoch 16/20\n",
      "164/164 [==============================] - 69s 422ms/step - loss: 1.5585 - val_loss: 1.7283\n",
      "Epoch 17/20\n",
      "164/164 [==============================] - 69s 421ms/step - loss: 1.5098 - val_loss: 1.7079\n",
      "Epoch 18/20\n",
      "164/164 [==============================] - 69s 420ms/step - loss: 1.4643 - val_loss: 1.6962\n",
      "Epoch 19/20\n",
      "164/164 [==============================] - 69s 421ms/step - loss: 1.4238 - val_loss: 1.6814\n",
      "Epoch 20/20\n",
      "164/164 [==============================] - 69s 423ms/step - loss: 1.3841 - val_loss: 1.6703\n",
      "Model: \"LSTM_Encoder-Decoder_Scratch\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Encoder (Encoder)            multiple                  10813700  \n",
      "_________________________________________________________________\n",
      "Decoder (Decoder)            multiple                  8965700   \n",
      "_________________________________________________________________\n",
      "Dense (Dense)                multiple                  2964350   \n",
      "=================================================================\n",
      "Total params: 22,743,750\n",
      "Trainable params: 22,743,750\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_L1 = build_model_lstm(embed='scratch', name='LSTM_Encoder-Decoder_Scratch')\n",
    "train_model(model_L1, 'LSTM_Encoder-Decoder_Scratch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZeVDp9sNJ2bq"
   },
   "outputs": [],
   "source": [
    "model_L1.save_weights(model_path + '1_1_LSTM_Scratch/' + '1_1_LSTM_Scratch', save_format='tf') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eBrkUqtNT6Pn"
   },
   "source": [
    "### Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xLxHBGdyHosF",
    "outputId": "3f42e516-bfb3-4301-fa1b-d542ec0192b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Text: At the party , the member has variety job .\n",
      "Output Text: At the party , the members have a variety of jobs .\n",
      "Predicted Text: At the school , the temperature is a big .\n",
      "====================================================================================================\n",
      "Input Text: Thank you NY .\n",
      "Output Text: Thank you , NY !\n",
      "Predicted Text: Thank you for me .\n",
      "====================================================================================================\n",
      "Input Text: Few last days have been strange .\n",
      "Output Text: The last few days have been strange .\n",
      "Predicted Text: A few days ago was not .\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "predict_result(train, model_L1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2_ca88lXHp6S",
    "outputId": "5fa1dfb6-c169-4b22-990d-a393b011358f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Text: Have you ever over the wall of school ?\n",
      "Output Text: Have you ever climbed over the wall at school ?\n",
      "Predicted Text: Have you ever seen the New Year 's house ?\n",
      "====================================================================================================\n",
      "Input Text: It is so narrow that I have to keep my body very fit everytime .\n",
      "Output Text: It is so narrow that I have to keep my body very fit all the time .\n",
      "Predicted Text: It is very hot because I have to give me how much it is in a good .\n",
      "====================================================================================================\n",
      "Input Text: You can check the maintenance is finished or not at twitter .\n",
      "Output Text: You can check whether the maintenance is finished or not on twitter .\n",
      "Predicted Text: You can not know on the DVD 's house ,\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "predict_result(test, model_L1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5T4Z87Jt4_uL",
    "outputId": "61582007-c888-49f9-efc1-b4d33185dc29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Avg. Train BLEU Score: 0.4479462706390938\n",
      "Avg. Test BLEU Score: 0.4402298645803892\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "get_BLEU(train, test, model_L1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "znEm4EfWh1b4"
   },
   "source": [
    "## Encoder-Decoder: Glove Embed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OOXvfV0KiDxi"
   },
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BKwbendkvLAr",
    "outputId": "6634fe84-1886-4e70-fc2b-7f25f854b438"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "164/164 [==============================] - 76s 262ms/step - loss: 3.4552 - val_loss: 3.0118\n",
      "Epoch 2/20\n",
      "164/164 [==============================] - 42s 253ms/step - loss: 3.0562 - val_loss: 2.8951\n",
      "Epoch 3/20\n",
      "164/164 [==============================] - 42s 254ms/step - loss: 2.9103 - val_loss: 2.7484\n",
      "Epoch 4/20\n",
      "164/164 [==============================] - 42s 256ms/step - loss: 2.7660 - val_loss: 2.6158\n",
      "Epoch 5/20\n",
      "164/164 [==============================] - 42s 257ms/step - loss: 2.6224 - val_loss: 2.4752\n",
      "Epoch 6/20\n",
      "164/164 [==============================] - 42s 258ms/step - loss: 2.4793 - val_loss: 2.3423\n",
      "Epoch 7/20\n",
      "164/164 [==============================] - 42s 258ms/step - loss: 2.3445 - val_loss: 2.2264\n",
      "Epoch 8/20\n",
      "164/164 [==============================] - 41s 252ms/step - loss: 2.2347 - val_loss: 2.1381\n",
      "Epoch 9/20\n",
      "164/164 [==============================] - 42s 256ms/step - loss: 2.1450 - val_loss: 2.0653\n",
      "Epoch 10/20\n",
      "164/164 [==============================] - 42s 256ms/step - loss: 2.0682 - val_loss: 2.0003\n",
      "Epoch 11/20\n",
      "164/164 [==============================] - 42s 258ms/step - loss: 1.9983 - val_loss: 1.9434\n",
      "Epoch 12/20\n",
      "164/164 [==============================] - 42s 259ms/step - loss: 1.9367 - val_loss: 1.8961\n",
      "Epoch 13/20\n",
      "164/164 [==============================] - 42s 258ms/step - loss: 1.8827 - val_loss: 1.8547\n",
      "Epoch 14/20\n",
      "164/164 [==============================] - 43s 260ms/step - loss: 1.8357 - val_loss: 1.8200\n",
      "Epoch 15/20\n",
      "164/164 [==============================] - 42s 256ms/step - loss: 1.7934 - val_loss: 1.7898\n",
      "Epoch 16/20\n",
      "164/164 [==============================] - 42s 259ms/step - loss: 1.7552 - val_loss: 1.7641\n",
      "Epoch 17/20\n",
      "164/164 [==============================] - 42s 258ms/step - loss: 1.7208 - val_loss: 1.7399\n",
      "Epoch 18/20\n",
      "164/164 [==============================] - 42s 256ms/step - loss: 1.6891 - val_loss: 1.7205\n",
      "Epoch 19/20\n",
      "164/164 [==============================] - 43s 262ms/step - loss: 1.6595 - val_loss: 1.7009\n",
      "Epoch 20/20\n",
      "164/164 [==============================] - 43s 259ms/step - loss: 1.6325 - val_loss: 1.6842\n",
      "Model: \"LSTM_Encoder-Decoder_Glove\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Encoder (Encoder)            multiple                  10813700  \n",
      "_________________________________________________________________\n",
      "Decoder (Decoder)            multiple                  8965700   \n",
      "_________________________________________________________________\n",
      "Dense (Dense)                multiple                  2964350   \n",
      "=================================================================\n",
      "Total params: 22,743,750\n",
      "Trainable params: 3,285,150\n",
      "Non-trainable params: 19,458,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_L2 = build_model_lstm(embed='glove', name='LSTM_Encoder-Decoder_Glove')\n",
    "train_model(model_L2, 'LSTM_Encoder-Decoder_Glove')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2JxZVdawNY_y"
   },
   "outputs": [],
   "source": [
    "model_L2.save_weights(model_path + '1_2_LSTM_Glove/' + '1_2_LSTM_Glove', save_format='tf') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vQ4WtkutiF6E"
   },
   "source": [
    "### Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Orx3Nac3GelE",
    "outputId": "cd5a26ef-9bc1-4484-8ca8-89a0d00c8019"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Text: At the party , the member has variety job .\n",
      "Output Text: At the party , the members have a variety of jobs .\n",
      "Predicted Text: In the way , the party , I have a job .\n",
      "====================================================================================================\n",
      "Input Text: Thank you NY .\n",
      "Output Text: Thank you , NY !\n",
      "Predicted Text: Thank you .\n",
      "====================================================================================================\n",
      "Input Text: Few last days have been strange .\n",
      "Output Text: The last few days have been strange .\n",
      "Predicted Text: These days ago .\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "predict_result(train, model_L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gqfw3sWLGgX4",
    "outputId": "1a573733-5fd0-44f5-8ec5-b04aa4677ef3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Text: Have you ever over the wall of school ?\n",
      "Output Text: Have you ever climbed over the wall at school ?\n",
      "Predicted Text: Do you have the difference of the difference of the hotel .\n",
      "====================================================================================================\n",
      "Input Text: It is so narrow that I have to keep my body very fit everytime .\n",
      "Output Text: It is so narrow that I have to keep my body very fit all the time .\n",
      "Predicted Text: It is so I feel that I have to be a very poor .\n",
      "====================================================================================================\n",
      "Input Text: You can check the maintenance is finished or not at twitter .\n",
      "Output Text: You can check whether the maintenance is finished or not on twitter .\n",
      "Predicted Text: I can not the internet or not my office , I .\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "predict_result(test, model_L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xXzKMGbn6dlQ",
    "outputId": "87133c1b-a4ee-4411-a567-6296d8ee349e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Avg. Train BLEU Score: 0.4487982872512108\n",
      "Avg. Test BLEU Score: 0.4329829866763378\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "get_BLEU(train, test, model_L2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EvkG9FlLi1xK"
   },
   "source": [
    "## Encoder-Decoder: FastText Embed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UDO1C3jKjDgs"
   },
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8fyLg2O5vNGm",
    "outputId": "b2e612c9-ea4d-49a4-91ad-54d0a89c5647"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "164/164 [==============================] - 51s 269ms/step - loss: 3.4884 - val_loss: 3.0198\n",
      "Epoch 2/20\n",
      "164/164 [==============================] - 42s 253ms/step - loss: 3.0620 - val_loss: 2.9038\n",
      "Epoch 3/20\n",
      "164/164 [==============================] - 42s 255ms/step - loss: 2.9126 - val_loss: 2.7379\n",
      "Epoch 4/20\n",
      "164/164 [==============================] - 42s 255ms/step - loss: 2.7339 - val_loss: 2.5750\n",
      "Epoch 5/20\n",
      "164/164 [==============================] - 42s 253ms/step - loss: 2.5881 - val_loss: 2.4493\n",
      "Epoch 6/20\n",
      "164/164 [==============================] - 42s 255ms/step - loss: 2.4677 - val_loss: 2.3480\n",
      "Epoch 7/20\n",
      "164/164 [==============================] - 42s 256ms/step - loss: 2.3696 - val_loss: 2.2632\n",
      "Epoch 8/20\n",
      "164/164 [==============================] - 42s 258ms/step - loss: 2.2848 - val_loss: 2.1911\n",
      "Epoch 9/20\n",
      "164/164 [==============================] - 41s 252ms/step - loss: 2.2103 - val_loss: 2.1257\n",
      "Epoch 10/20\n",
      "164/164 [==============================] - 42s 257ms/step - loss: 2.1414 - val_loss: 2.0633\n",
      "Epoch 11/20\n",
      "164/164 [==============================] - 42s 258ms/step - loss: 2.0778 - val_loss: 2.0104\n",
      "Epoch 12/20\n",
      "164/164 [==============================] - 42s 258ms/step - loss: 2.0210 - val_loss: 1.9655\n",
      "Epoch 13/20\n",
      "164/164 [==============================] - 43s 262ms/step - loss: 1.9712 - val_loss: 1.9239\n",
      "Epoch 14/20\n",
      "164/164 [==============================] - 42s 256ms/step - loss: 1.9252 - val_loss: 1.8853\n",
      "Epoch 15/20\n",
      "164/164 [==============================] - 43s 259ms/step - loss: 1.8832 - val_loss: 1.8535\n",
      "Epoch 16/20\n",
      "164/164 [==============================] - 43s 259ms/step - loss: 1.8450 - val_loss: 1.8234\n",
      "Epoch 17/20\n",
      "164/164 [==============================] - 43s 260ms/step - loss: 1.8101 - val_loss: 1.7956\n",
      "Epoch 18/20\n",
      "164/164 [==============================] - 42s 259ms/step - loss: 1.7772 - val_loss: 1.7694\n",
      "Epoch 19/20\n",
      "164/164 [==============================] - 42s 256ms/step - loss: 1.7468 - val_loss: 1.7463\n",
      "Epoch 20/20\n",
      "164/164 [==============================] - 42s 258ms/step - loss: 1.7175 - val_loss: 1.7253\n",
      "Model: \"LSTM_Encoder-Decoder_Fast\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Encoder (Encoder)            multiple                  10813700  \n",
      "_________________________________________________________________\n",
      "Decoder (Decoder)            multiple                  8965700   \n",
      "_________________________________________________________________\n",
      "Dense (Dense)                multiple                  2964350   \n",
      "=================================================================\n",
      "Total params: 22,743,750\n",
      "Trainable params: 3,285,150\n",
      "Non-trainable params: 19,458,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_L3 = build_model_lstm(embed='fast', name='LSTM_Encoder-Decoder_Fast')\n",
    "train_model(model_L3, 'LSTM_Encoder-Decoder_Fast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FxbBTkgmNq4l"
   },
   "outputs": [],
   "source": [
    "model_L3.save_weights(model_path + '1_3_LSTM_Fast/' + '1_3_LSTM_Fast', save_format='tf') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KsTOgTjqji1D"
   },
   "source": [
    "### Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QliToLwLLwkz",
    "outputId": "3af3a973-6c0b-4928-e6db-6ee6a3c36e48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Text: At the party , the member has variety job .\n",
      "Output Text: At the party , the members have a variety of jobs .\n",
      "Predicted Text: In the other hand , the first day .\n",
      "====================================================================================================\n",
      "Input Text: Thank you NY .\n",
      "Output Text: Thank you , NY !\n",
      "Predicted Text: Thank you .\n",
      "====================================================================================================\n",
      "Input Text: Few last days have been strange .\n",
      "Output Text: The last few days have been strange .\n",
      "Predicted Text: A few days ago , it is the most .\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "predict_result(train, model_L3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oiRTeyZHLyXD",
    "outputId": "cf678994-0737-437d-bac8-f69d61ec407c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Text: Have you ever over the wall of school ?\n",
      "Output Text: Have you ever climbed over the wall at school ?\n",
      "Predicted Text: Have you have a new of the next time .\n",
      "====================================================================================================\n",
      "Input Text: It is so narrow that I have to keep my body very fit everytime .\n",
      "Output Text: It is so narrow that I have to keep my body very fit all the time .\n",
      "Predicted Text: It is so I have a little bit that I will be able to improve my English .\n",
      "====================================================================================================\n",
      "Input Text: You can check the maintenance is finished or not at twitter .\n",
      "Output Text: You can check whether the maintenance is finished or not on twitter .\n",
      "Predicted Text: You can not get up on the book in the U .\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "predict_result(test, model_L3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iMw94-UW6pnl",
    "outputId": "6bb2396b-5fc0-4abd-b545-a11eecc5d864"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Avg. Train BLEU Score: 0.4390916524172069\n",
      "Avg. Test BLEU Score: 0.46569867802376036\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "get_BLEU(train, test, model_L3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NOewPOaHpJlu"
   },
   "source": [
    "# Bidirectional LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dND_drWPpJlu"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    '''\n",
    "    Encoder model -- That takes a input sequence and returns encoder-outputs,encoder_final_state_h,encoder_final_state_c\n",
    "    '''\n",
    "    def __init__(self,in_vocab_size,embedding_dim,enc_units,input_length,embed,name='Encoder'):\n",
    "        super().__init__(name=name)\n",
    "        self.in_vocab_size = in_vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.input_length = input_length\n",
    "        self.enc_units = enc_units\n",
    "        self.embed = embed\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if self.embed == 'scratch':\n",
    "            self.embedding = Embedding(input_dim=self.in_vocab_size, output_dim=self.embedding_dim, input_length=self.input_length, mask_zero=True, name=\"Encoder_Embedding\")\n",
    "        elif self.embed == 'glove':\n",
    "            self.embedding = Embedding(input_dim=self.in_vocab_size, output_dim=self.embedding_dim, input_length=self.input_length, mask_zero=True, weights=[encoder_embedding_matrix_glove], trainable=False, name=\"Encoder_Embedding\")\n",
    "        elif self.embed == 'fast':\n",
    "            self.embedding = Embedding(input_dim=self.in_vocab_size, output_dim=self.embedding_dim, input_length=self.input_length, mask_zero=True, weights=[encoder_embedding_matrix_fast], trainable=False, name=\"Encoder_Embedding\")\n",
    "\n",
    "        self.lstm = Bidirectional(LSTM(self.enc_units, return_state=True, return_sequences=True, name=\"Encoder_LSTM\"))\n",
    "        \n",
    "    def call(self, input_sentences, training=True):\n",
    "        input_embed = self.embedding(input_sentences)\n",
    "        encoder_output, encoder_state_h_fwd, encoder_state_c_fwd, encoder_state_h_bwd, encoder_state_c_bwd = self.lstm(input_embed)\n",
    "        encoder_state_h = Concatenate()([encoder_state_h_fwd, encoder_state_h_bwd])\n",
    "        encoder_state_c = Concatenate()([encoder_state_c_fwd, encoder_state_c_bwd])\n",
    "        return encoder_output, encoder_state_h, encoder_state_c\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------\n",
    "class Decoder(tf.keras.Model):\n",
    "    '''\n",
    "    Decoder model -- That takes a input sequence and returns output sequence\n",
    "    '''\n",
    "    def __init__(self,out_vocab_size,embedding_dim,dec_units,input_length,embed,name='Decoder'):\n",
    "        super().__init__(name=name)\n",
    "        self.out_vocab_size = out_vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.dec_units = dec_units\n",
    "        self.input_length = input_length\n",
    "        self.embed = embed\n",
    "     \n",
    "    def build(self, input_shape):\n",
    "        if self.embed == 'scratch':\n",
    "            self.embedding = Embedding(input_dim=self.out_vocab_size, output_dim=self.embedding_dim, input_length=self.input_length, mask_zero=True, name=\"Decoder_Embedding\")\n",
    "        elif self.embed == 'glove':\n",
    "            self.embedding = Embedding(input_dim=self.out_vocab_size, output_dim=self.embedding_dim, input_length=self.input_length, mask_zero=True, weights=[decoder_embedding_matrix_glove], trainable=False, name=\"Decoder_Embedding\")\n",
    "        elif self.embed == 'fast':\n",
    "            self.embedding = Embedding(input_dim=self.out_vocab_size, output_dim=self.embedding_dim, input_length=self.input_length, mask_zero=True, weights=[decoder_embedding_matrix_fast], trainable=False, name=\"Decoder_Embedding\")\n",
    "\n",
    "        self.lstm = LSTM(self.dec_units*2, return_sequences=True, return_state=True, name=\"Decoder_LSTM\")\n",
    "        \n",
    "    def call(self,target_sentences,initial_states):\n",
    "        target_embedd = self.embedding(target_sentences)\n",
    "        decoder_output, decoder_final_state_h, decoder_final_state_c = self.lstm(target_embedd, initial_state=initial_states)\n",
    "        return decoder_output, decoder_final_state_h, decoder_final_state_c\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------\n",
    "class Encoder_Decoder(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, encoder_inputs_length, decoder_inputs_length, in_vocab_size, out_vocab_size, embedding_dim, enc_units, dec_units, embed, name='Encoder-Decoder'):\n",
    "        super().__init__(name=name)\n",
    "        self.encoder = Encoder(in_vocab_size=in_vocab_size+1, embedding_dim=embedding_dim, enc_units=enc_units, input_length=encoder_inputs_length, embed=embed)\n",
    "        self.decoder = Decoder(out_vocab_size=out_vocab_size+1, embedding_dim=embedding_dim, dec_units=dec_units, input_length=decoder_inputs_length, embed=embed)\n",
    "        self.dense   = Dense(out_vocab_size, activation='softmax', name='Dense')\n",
    "    \n",
    "    def call(self, data):\n",
    "        input, output = data[0], data[1]\n",
    "\n",
    "        encoder_output, encoder_h, encoder_c = self.encoder(input)\n",
    "        decoder_output, decoder_h, decoder_c = self.decoder(output, [encoder_h, encoder_c])\n",
    "        output                               = self.dense(decoder_output)\n",
    "        return output\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------\n",
    "def build_model_bilstm(embed, name):\n",
    "  model = Encoder_Decoder(encoder_inputs_length=25, decoder_inputs_length=25, in_vocab_size=vocab_size_input, out_vocab_size=vocab_size_output,embedding_dim=300, enc_units=100, dec_units=100, embed=embed, name=name)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hGqvi3kgpJlu"
   },
   "source": [
    "## Encoder-Decoder: Scratch Embed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t3O3Y1MwpJlv"
   },
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4nDAcad20oVn",
    "outputId": "6d527aeb-7b36-4943-f635-6622a1b125b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "164/164 [==============================] - 101s 560ms/step - loss: 3.3626 - val_loss: 2.9025\n",
      "Epoch 2/20\n",
      "164/164 [==============================] - 89s 543ms/step - loss: 2.8692 - val_loss: 2.6561\n",
      "Epoch 3/20\n",
      "164/164 [==============================] - 88s 538ms/step - loss: 2.6278 - val_loss: 2.4397\n",
      "Epoch 4/20\n",
      "164/164 [==============================] - 89s 541ms/step - loss: 2.4127 - val_loss: 2.2772\n",
      "Epoch 5/20\n",
      "164/164 [==============================] - 89s 544ms/step - loss: 2.2615 - val_loss: 2.1635\n",
      "Epoch 6/20\n",
      "164/164 [==============================] - 89s 543ms/step - loss: 2.1397 - val_loss: 2.0731\n",
      "Epoch 7/20\n",
      "164/164 [==============================] - 89s 541ms/step - loss: 2.0382 - val_loss: 2.0004\n",
      "Epoch 8/20\n",
      "164/164 [==============================] - 89s 545ms/step - loss: 1.9473 - val_loss: 1.9340\n",
      "Epoch 9/20\n",
      "164/164 [==============================] - 88s 538ms/step - loss: 1.8615 - val_loss: 1.8732\n",
      "Epoch 10/20\n",
      "164/164 [==============================] - 89s 541ms/step - loss: 1.7806 - val_loss: 1.8191\n",
      "Epoch 11/20\n",
      "164/164 [==============================] - 89s 545ms/step - loss: 1.7036 - val_loss: 1.7703\n",
      "Epoch 12/20\n",
      "164/164 [==============================] - 90s 545ms/step - loss: 1.6303 - val_loss: 1.7261\n",
      "Epoch 13/20\n",
      "164/164 [==============================] - 91s 557ms/step - loss: 1.5615 - val_loss: 1.6929\n",
      "Epoch 14/20\n",
      "164/164 [==============================] - 89s 542ms/step - loss: 1.4976 - val_loss: 1.6580\n",
      "Epoch 15/20\n",
      "164/164 [==============================] - 89s 545ms/step - loss: 1.4371 - val_loss: 1.6325\n",
      "Epoch 16/20\n",
      "164/164 [==============================] - 88s 535ms/step - loss: 1.3806 - val_loss: 1.6088\n",
      "Epoch 17/20\n",
      "164/164 [==============================] - 91s 552ms/step - loss: 1.3265 - val_loss: 1.5889\n",
      "Epoch 18/20\n",
      "164/164 [==============================] - 90s 546ms/step - loss: 1.2771 - val_loss: 1.5708\n",
      "Epoch 19/20\n",
      "164/164 [==============================] - 89s 542ms/step - loss: 1.2298 - val_loss: 1.5551\n",
      "Epoch 20/20\n",
      "164/164 [==============================] - 88s 534ms/step - loss: 1.1840 - val_loss: 1.5438\n",
      "Model: \"BiLSTM_Encoder-Decoder_Scratch\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Encoder (Encoder)            multiple                  10974100  \n",
      "_________________________________________________________________\n",
      "Decoder (Decoder)            multiple                  9206100   \n",
      "_________________________________________________________________\n",
      "Dense (Dense)                multiple                  5899350   \n",
      "=================================================================\n",
      "Total params: 26,079,550\n",
      "Trainable params: 26,079,550\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_BL1 = build_model_bilstm(embed='scratch', name='BiLSTM_Encoder-Decoder_Scratch')\n",
    "train_model(model_BL1, 'BiLSTM_Encoder-Decoder_Scratch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zzfp9w9iNzzV"
   },
   "outputs": [],
   "source": [
    "model_BL1.save_weights(model_path + '2_1_BiLSTM_Scratch/' + '2_1_BiLSTM_Scratch', save_format='tf') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RNSc7RlypJlv"
   },
   "source": [
    "### Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lGAaRZY2L1Sf",
    "outputId": "8eb9688d-0c14-45c2-d823-e2453384d260"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Text: At the party , the member has variety job .\n",
      "Output Text: At the party , the members have a variety of jobs .\n",
      "Predicted Text: At the party , a job has a boyfriend .\n",
      "====================================================================================================\n",
      "Input Text: Thank you NY .\n",
      "Output Text: Thank you , NY !\n",
      "Predicted Text: Thank you guys .\n",
      "====================================================================================================\n",
      "Input Text: Few last days have been strange .\n",
      "Output Text: The last few days have been strange .\n",
      "Predicted Text: A few days ago , it was not .\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "predict_result(train, model_BL1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BfqvntGML2zY",
    "outputId": "d9b0e20d-989e-4d41-9c52-41116c27d819"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Text: Have you ever over the wall of school ?\n",
      "Output Text: Have you ever climbed over the wall at school ?\n",
      "Predicted Text: Have you ever been over the school of a family ?\n",
      "====================================================================================================\n",
      "Input Text: It is so narrow that I have to keep my body very fit everytime .\n",
      "Output Text: It is so narrow that I have to keep my body very fit all the time .\n",
      "Predicted Text: It is so hard to do my best and it 's not free .\n",
      "====================================================================================================\n",
      "Input Text: You can check the maintenance is finished or not at twitter .\n",
      "Output Text: You can check whether the maintenance is finished or not on twitter .\n",
      "Predicted Text: You can not get a special service or not in the internet .\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "predict_result(test, model_BL1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eCI1HZTF6rNY",
    "outputId": "68333ba8-6a54-4d9f-aa8d-1f6a59aceb2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Avg. Train BLEU Score: 0.43750467220453443\n",
      "Avg. Test BLEU Score: 0.4257227891921617\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "get_BLEU(train, test, model_BL1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9kk5XUNypJlw"
   },
   "source": [
    "## Encoder-Decoder: Glove Embed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5fZrXBAvpJly"
   },
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z0kI5awh05Tb",
    "outputId": "aa0f00c5-d122-4cc6-a12b-fa745aee01cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "164/164 [==============================] - 71s 381ms/step - loss: 3.2611 - val_loss: 2.8714\n",
      "Epoch 2/20\n",
      "164/164 [==============================] - 60s 365ms/step - loss: 2.8770 - val_loss: 2.6858\n",
      "Epoch 3/20\n",
      "164/164 [==============================] - 59s 361ms/step - loss: 2.6522 - val_loss: 2.4620\n",
      "Epoch 4/20\n",
      "164/164 [==============================] - 59s 359ms/step - loss: 2.4324 - val_loss: 2.2653\n",
      "Epoch 5/20\n",
      "164/164 [==============================] - 59s 361ms/step - loss: 2.2425 - val_loss: 2.1121\n",
      "Epoch 6/20\n",
      "164/164 [==============================] - 59s 360ms/step - loss: 2.0941 - val_loss: 1.9961\n",
      "Epoch 7/20\n",
      "164/164 [==============================] - 60s 365ms/step - loss: 1.9739 - val_loss: 1.9006\n",
      "Epoch 8/20\n",
      "164/164 [==============================] - 59s 360ms/step - loss: 1.8749 - val_loss: 1.8255\n",
      "Epoch 9/20\n",
      "164/164 [==============================] - 59s 357ms/step - loss: 1.7920 - val_loss: 1.7675\n",
      "Epoch 10/20\n",
      "164/164 [==============================] - 59s 359ms/step - loss: 1.7202 - val_loss: 1.7162\n",
      "Epoch 11/20\n",
      "164/164 [==============================] - 59s 362ms/step - loss: 1.6556 - val_loss: 1.6673\n",
      "Epoch 12/20\n",
      "164/164 [==============================] - 59s 360ms/step - loss: 1.5960 - val_loss: 1.6257\n",
      "Epoch 13/20\n",
      "164/164 [==============================] - 60s 369ms/step - loss: 1.5404 - val_loss: 1.5901\n",
      "Epoch 14/20\n",
      "164/164 [==============================] - 60s 363ms/step - loss: 1.4902 - val_loss: 1.5592\n",
      "Epoch 15/20\n",
      "164/164 [==============================] - 59s 360ms/step - loss: 1.4429 - val_loss: 1.5313\n",
      "Epoch 16/20\n",
      "164/164 [==============================] - 59s 362ms/step - loss: 1.4005 - val_loss: 1.5098\n",
      "Epoch 17/20\n",
      "164/164 [==============================] - 59s 361ms/step - loss: 1.3615 - val_loss: 1.4882\n",
      "Epoch 18/20\n",
      "164/164 [==============================] - 60s 366ms/step - loss: 1.3245 - val_loss: 1.4691\n",
      "Epoch 19/20\n",
      "164/164 [==============================] - 59s 360ms/step - loss: 1.2917 - val_loss: 1.4543\n",
      "Epoch 20/20\n",
      "164/164 [==============================] - 59s 359ms/step - loss: 1.2600 - val_loss: 1.4426\n",
      "Model: \"BiLSTM_Encoder-Decoder_Glove\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Encoder (Encoder)            multiple                  10974100  \n",
      "_________________________________________________________________\n",
      "Decoder (Decoder)            multiple                  9206100   \n",
      "_________________________________________________________________\n",
      "Dense (Dense)                multiple                  5899350   \n",
      "=================================================================\n",
      "Total params: 26,079,550\n",
      "Trainable params: 6,620,950\n",
      "Non-trainable params: 19,458,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_BL2 = build_model_bilstm(embed='glove', name='BiLSTM_Encoder-Decoder_Glove')\n",
    "train_model(model_BL2, 'BiLSTM_Encoder-Decoder_Glove')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ywW-rugdOCr-"
   },
   "outputs": [],
   "source": [
    "model_BL2.save_weights(model_path + '2_2_BiLSTM_Glove/' + '2_2_BiLSTM_Glove', save_format='tf') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fkACav8zpJly"
   },
   "source": [
    "### Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "izd0NstZL44L",
    "outputId": "814c9359-397c-471c-8123-9ad4cc84722b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Text: At the party , the member has variety job .\n",
      "Output Text: At the party , the members have a variety of jobs .\n",
      "Predicted Text: In the party , the party has a job .\n",
      "====================================================================================================\n",
      "Input Text: Thank you NY .\n",
      "Output Text: Thank you , NY !\n",
      "Predicted Text: Thank you .\n",
      "====================================================================================================\n",
      "Input Text: Few last days have been strange .\n",
      "Output Text: The last few days have been strange .\n",
      "Predicted Text: The last week has been a little .\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "predict_result(train, model_BL2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4SFJ_sAqL6cs",
    "outputId": "a0e0d6dc-6628-4859-c450-5b42ecac051d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Text: Have you ever over the wall of school ?\n",
      "Output Text: Have you ever climbed over the wall at school ?\n",
      "Predicted Text: Have you ever seen the middle of the office ?\n",
      "====================================================================================================\n",
      "Input Text: It is so narrow that I have to keep my body very fit everytime .\n",
      "Output Text: It is so narrow that I have to keep my body very fit all the time .\n",
      "Predicted Text: It is so that I have to be able to keep my body very much .\n",
      "====================================================================================================\n",
      "Input Text: You can check the maintenance is finished or not at twitter .\n",
      "Output Text: You can check whether the maintenance is finished or not on twitter .\n",
      "Predicted Text: I can check the next or not the main or I .\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "predict_result(test, model_BL2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7-4aU5i96sKk",
    "outputId": "fa1f8f0c-c176-4448-d66a-bd7c4be432d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Avg. Train BLEU Score: 0.4293580872742956\n",
      "Avg. Test BLEU Score: 0.42601507482548406\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "get_BLEU(train, test, model_BL2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8YcD_ofppJly"
   },
   "source": [
    "## Encoder-Decoder: FastText Embed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3D1DX0tXpJlz"
   },
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BDRLGUk61Fcn",
    "outputId": "97a88732-f5d9-44c4-9861-503a9672328b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "164/164 [==============================] - 71s 379ms/step - loss: 3.2892 - val_loss: 2.8843\n",
      "Epoch 2/20\n",
      "164/164 [==============================] - 59s 360ms/step - loss: 2.9150 - val_loss: 2.7392\n",
      "Epoch 3/20\n",
      "164/164 [==============================] - 59s 362ms/step - loss: 2.7050 - val_loss: 2.5128\n",
      "Epoch 4/20\n",
      "164/164 [==============================] - 59s 359ms/step - loss: 2.4953 - val_loss: 2.3389\n",
      "Epoch 5/20\n",
      "164/164 [==============================] - 59s 362ms/step - loss: 2.3338 - val_loss: 2.2027\n",
      "Epoch 6/20\n",
      "164/164 [==============================] - 59s 360ms/step - loss: 2.2018 - val_loss: 2.0928\n",
      "Epoch 7/20\n",
      "164/164 [==============================] - 59s 361ms/step - loss: 2.0928 - val_loss: 2.0033\n",
      "Epoch 8/20\n",
      "164/164 [==============================] - 60s 365ms/step - loss: 2.0034 - val_loss: 1.9322\n",
      "Epoch 9/20\n",
      "164/164 [==============================] - 59s 357ms/step - loss: 1.9277 - val_loss: 1.8689\n",
      "Epoch 10/20\n",
      "164/164 [==============================] - 59s 359ms/step - loss: 1.8591 - val_loss: 1.8156\n",
      "Epoch 11/20\n",
      "164/164 [==============================] - 60s 364ms/step - loss: 1.7957 - val_loss: 1.7618\n",
      "Epoch 12/20\n",
      "164/164 [==============================] - 59s 360ms/step - loss: 1.7381 - val_loss: 1.7202\n",
      "Epoch 13/20\n",
      "164/164 [==============================] - 60s 364ms/step - loss: 1.6852 - val_loss: 1.6790\n",
      "Epoch 14/20\n",
      "164/164 [==============================] - 59s 361ms/step - loss: 1.6347 - val_loss: 1.6388\n",
      "Epoch 15/20\n",
      "164/164 [==============================] - 60s 362ms/step - loss: 1.5863 - val_loss: 1.6032\n",
      "Epoch 16/20\n",
      "164/164 [==============================] - 59s 361ms/step - loss: 1.5403 - val_loss: 1.5694\n",
      "Epoch 17/20\n",
      "164/164 [==============================] - 59s 362ms/step - loss: 1.4970 - val_loss: 1.5446\n",
      "Epoch 18/20\n",
      "164/164 [==============================] - 60s 365ms/step - loss: 1.4575 - val_loss: 1.5176\n",
      "Epoch 19/20\n",
      "164/164 [==============================] - 60s 364ms/step - loss: 1.4198 - val_loss: 1.4916\n",
      "Epoch 20/20\n",
      "164/164 [==============================] - 59s 361ms/step - loss: 1.3845 - val_loss: 1.4671\n",
      "Model: \"BiLSTM_Encoder-Decoder_Fast\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Encoder (Encoder)            multiple                  10974100  \n",
      "_________________________________________________________________\n",
      "Decoder (Decoder)            multiple                  9206100   \n",
      "_________________________________________________________________\n",
      "Dense (Dense)                multiple                  5899350   \n",
      "=================================================================\n",
      "Total params: 26,079,550\n",
      "Trainable params: 6,620,950\n",
      "Non-trainable params: 19,458,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_BL3 = build_model_bilstm(embed='fast', name='BiLSTM_Encoder-Decoder_Fast')\n",
    "train_model(model_BL3, 'BiLSTM_Encoder-Decoder_Fast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vf_clk03OK6N"
   },
   "outputs": [],
   "source": [
    "model_BL3.save_weights(model_path + '2_3_BiLSTM_Fast/' + '2_3_BiLSTM_Fast', save_format='tf') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SqT83-wYpJlz"
   },
   "source": [
    "### Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lUQjrDxrL83_",
    "outputId": "60c496a7-2b2b-4e63-e50f-3ab19e1914fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Text: At the party , the member has variety job .\n",
      "Output Text: At the party , the members have a variety of jobs .\n",
      "Predicted Text: At the other hand , a job is a party .\n",
      "====================================================================================================\n",
      "Input Text: Thank you NY .\n",
      "Output Text: Thank you , NY !\n",
      "Predicted Text: Thank you for reading .\n",
      "====================================================================================================\n",
      "Input Text: Few last days have been strange .\n",
      "Output Text: The last few days have been strange .\n",
      "Predicted Text: A few days ago .\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "predict_result(train, model_BL3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "63gxysRuL-bN",
    "outputId": "cccc2609-30a6-4169-9fb8-37f34f451b9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Text: Have you ever over the wall of school ?\n",
      "Output Text: Have you ever climbed over the wall at school ?\n",
      "Predicted Text: Have you ever one of the party of the school ?\n",
      "====================================================================================================\n",
      "Input Text: It is so narrow that I have to keep my body very fit everytime .\n",
      "Output Text: It is so narrow that I have to keep my body very fit all the time .\n",
      "Predicted Text: It is so much because I will be able to my face .\n",
      "====================================================================================================\n",
      "Input Text: You can check the maintenance is finished or not at twitter .\n",
      "Output Text: You can check whether the maintenance is finished or not on twitter .\n",
      "Predicted Text: You can not check the test , I should get the right .\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "predict_result(test, model_BL3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cLqpzvvL6tOi",
    "outputId": "c49cfdd8-efb2-4445-9886-32d201c1f058"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Avg. Train BLEU Score: 0.4262674491548774\n",
      "Avg. Test BLEU Score: 0.4179576372366596\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "get_BLEU(train, test, model_BL3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XWqmAu3QQzMT"
   },
   "source": [
    "# GRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yJbcd-GbK97J"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    '''\n",
    "    Encoder model -- That takes a input sequence and returns encoder-outputs,encoder_final_state_h,encoder_final_state_c\n",
    "    '''\n",
    "    def __init__(self,in_vocab_size,embedding_dim,enc_units,input_length,embed,name='Encoder'):\n",
    "        super().__init__(name=name)\n",
    "        self.in_vocab_size = in_vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.input_length = input_length\n",
    "        self.enc_units = enc_units\n",
    "        self.embed = embed\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if self.embed == 'scratch':\n",
    "            self.embedding = Embedding(input_dim=self.in_vocab_size, output_dim=self.embedding_dim, input_length=self.input_length, mask_zero=True, name=\"Encoder_Embedding\")\n",
    "        elif self.embed == 'glove':\n",
    "            self.embedding = Embedding(input_dim=self.in_vocab_size, output_dim=self.embedding_dim, input_length=self.input_length, mask_zero=True, weights=[encoder_embedding_matrix_glove], trainable=False, name=\"Encoder_Embedding\")\n",
    "        elif self.embed == 'fast':\n",
    "            self.embedding = Embedding(input_dim=self.in_vocab_size, output_dim=self.embedding_dim, input_length=self.input_length, mask_zero=True, weights=[encoder_embedding_matrix_fast], trainable=False, name=\"Encoder_Embedding\")\n",
    "\n",
    "        self.gru = GRU(self.enc_units, return_state=True, return_sequences=True, name=\"Encoder_GRU\")\n",
    "        \n",
    "    def call(self,input_sentences,training=True):\n",
    "        input_embed = self.embedding(input_sentences)\n",
    "        encoder_output, encoder_state_h = self.gru(input_embed)\n",
    "        return encoder_output, encoder_state_h\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------\n",
    "class Decoder(tf.keras.Model):\n",
    "    '''\n",
    "    Decoder model -- That takes a input sequence and returns output sequence\n",
    "    '''\n",
    "    def __init__(self,out_vocab_size,embedding_dim,dec_units,input_length,embed,name='Decoder'):\n",
    "        super().__init__(name=name)\n",
    "        self.out_vocab_size = out_vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.dec_units = dec_units\n",
    "        self.input_length = input_length\n",
    "        self.embed = embed\n",
    "     \n",
    "    def build(self, input_shape):\n",
    "        if self.embed == 'scratch':\n",
    "            self.embedding = Embedding(input_dim=self.out_vocab_size, output_dim=self.embedding_dim, input_length=self.input_length, mask_zero=True, name=\"Decoder_Embedding\")\n",
    "        elif self.embed == 'glove':\n",
    "            self.embedding = Embedding(input_dim=self.out_vocab_size, output_dim=self.embedding_dim, input_length=self.input_length, mask_zero=True, weights=[decoder_embedding_matrix_glove], trainable=False, name=\"Decoder_Embedding\")\n",
    "        elif self.embed == 'fast':\n",
    "            self.embedding = Embedding(input_dim=self.out_vocab_size, output_dim=self.embedding_dim, input_length=self.input_length, mask_zero=True, weights=[decoder_embedding_matrix_fast], trainable=False, name=\"Decoder_Embedding\")\n",
    "\n",
    "        self.gru = GRU(self.dec_units, return_sequences=True, return_state=True, name=\"Decoder_GRU\")\n",
    "        \n",
    "    def call(self,target_sentences,initial_states):\n",
    "        target_embedd = self.embedding(target_sentences)\n",
    "        decoder_output, decoder_final_state_h = self.gru(target_embedd, initial_state=initial_states)\n",
    "        return decoder_output, decoder_final_state_h\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------\n",
    "class Encoder_Decoder(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, encoder_inputs_length, decoder_inputs_length, in_vocab_size, out_vocab_size, embedding_dim, enc_units, dec_units, embed, name='Encoder-Decoder'):\n",
    "        super().__init__(name=name)\n",
    "        self.encoder = Encoder(in_vocab_size=in_vocab_size+1, embedding_dim=embedding_dim, enc_units=enc_units, input_length=encoder_inputs_length, embed=embed)\n",
    "        self.decoder = Decoder(out_vocab_size=out_vocab_size+1, embedding_dim=embedding_dim, dec_units=dec_units, input_length=decoder_inputs_length, embed=embed)\n",
    "        self.dense   = Dense(out_vocab_size, activation='softmax', name='Dense')\n",
    "    \n",
    "    def call(self, data):\n",
    "        input, output = data[0], data[1]\n",
    "\n",
    "        encoder_output, encoder_h = self.encoder(input)\n",
    "        decoder_output, decoder_h = self.decoder(output, encoder_h)\n",
    "        output                    = self.dense(decoder_output)\n",
    "        return output\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------\n",
    "def build_model_gru(embed, name):\n",
    "  model = Encoder_Decoder(encoder_inputs_length=25, decoder_inputs_length=25, in_vocab_size=vocab_size_input, out_vocab_size=vocab_size_output,embedding_dim=300, enc_units=100, dec_units=100, embed=embed, name=name)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MHtk8T0n7hBN"
   },
   "outputs": [],
   "source": [
    "def predict(input_sentence, model):\n",
    " \n",
    "  DECODER_SEQ_LEN = 25\n",
    "  predict_word_idx = np.zeros((1, 1))\n",
    "  predict_word_idx[0,0] = 1\n",
    "  predicted_sentence = ''\n",
    "\n",
    "  input_sequence=tokenizer_i.texts_to_sequences([input_sentence])\n",
    "  inputs=pad_sequences(input_sequence,maxlen=25,padding='post')\n",
    "  inputs=tf.convert_to_tensor(inputs)\n",
    "\n",
    "  enc_output, enc_state_h = model.layers[0](inputs)\n",
    "  states_values = enc_state_h\n",
    "\n",
    "  for i in range(DECODER_SEQ_LEN):\n",
    "        predict_emb = model.layers[1].embedding(predict_word_idx)\n",
    "        [dec_output, dec_state_h] = model.layers[1].gru(predict_emb, initial_state=states_values)\n",
    "        dec_output = model.layers[2](dec_output)\n",
    "        states_values = dec_state_h\n",
    "\n",
    "        predict_word_idx = np.reshape(np.argmax(dec_output), (1, 1))\n",
    "        predicted_sentence += ' ' + tokenizer_o.index_word[int(predict_word_idx)]\n",
    "\n",
    "        if tokenizer_o.word_index['<end>'] == predict_word_idx:\n",
    "            return predicted_sentence\n",
    "   \n",
    "  return predicted_sentence\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------\n",
    "def predict_result(data, model):\n",
    "    for i in range(len(data[:3])):\n",
    "        print(\"Input Text:\", data['input_text'].iloc[i])\n",
    "        print(\"Output Text:\", ' '.join(data['output_text_out'].iloc[i].split()[:-1]))\n",
    "        print(\"Predicted Text:\", ' '.join(predict(data['input_text'].iloc[i], model).split()[:-1]))\n",
    "        print('='*100)\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------\n",
    "def get_BLEU(train, test, model):\n",
    "    total_bleu=0\n",
    "    input_range = 100\n",
    "    for i in range(0,input_range):\n",
    "        output_sentence = ' '.join(train['output_text_out'].iloc[i].split()[:-1])\n",
    "        predicted_sentence = ' '.join(predict(train['input_text'].iloc[i], model).split()[:-1])\n",
    "        output_sentence = [output_sentence.split()]\n",
    "        predicted_sentence = predicted_sentence.split()\n",
    "        bleu_score = bleu.sentence_bleu(output_sentence, predicted_sentence)\n",
    "        total_bleu += bleu_score\n",
    "    train_avg_bleu = total_bleu/input_range\n",
    "\n",
    "    total_bleu=0\n",
    "    input_range = 100\n",
    "    for i in range(0,input_range):\n",
    "        output_sentence = ' '.join(test['output_text_out'].iloc[i].split()[:-1])\n",
    "        predicted_sentence = ' '.join(predict(test['input_text'].iloc[i], model).split()[:-1])\n",
    "        output_sentence = [output_sentence.split()]\n",
    "        predicted_sentence = predicted_sentence.split()\n",
    "        bleu_score = bleu.sentence_bleu(output_sentence, predicted_sentence)\n",
    "        total_bleu += bleu_score\n",
    "    test_avg_bleu = total_bleu/input_range\n",
    "\n",
    "    print('='*50)\n",
    "    print('Avg. Train BLEU Score:', train_avg_bleu)\n",
    "    print('Avg. Test BLEU Score:', test_avg_bleu)\n",
    "    print('='*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "epfymVp8K3Rm"
   },
   "source": [
    "## Encoder-Decoder: Scratch Embed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zqyzRC2qLClS"
   },
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qRlyQRH_2xQH",
    "outputId": "acfa0ab5-2305-42c8-f7f3-27356d91a4d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "164/164 [==============================] - 80s 447ms/step - loss: 3.5315 - val_loss: 3.0060\n",
      "Epoch 2/20\n",
      "164/164 [==============================] - 72s 438ms/step - loss: 3.0467 - val_loss: 2.8851\n",
      "Epoch 3/20\n",
      "164/164 [==============================] - 71s 435ms/step - loss: 2.8865 - val_loss: 2.6734\n",
      "Epoch 4/20\n",
      "164/164 [==============================] - 72s 437ms/step - loss: 2.6177 - val_loss: 2.4228\n",
      "Epoch 5/20\n",
      "164/164 [==============================] - 72s 437ms/step - loss: 2.4107 - val_loss: 2.2823\n",
      "Epoch 6/20\n",
      "164/164 [==============================] - 72s 437ms/step - loss: 2.2676 - val_loss: 2.1715\n",
      "Epoch 7/20\n",
      "164/164 [==============================] - 72s 439ms/step - loss: 2.1503 - val_loss: 2.0881\n",
      "Epoch 8/20\n",
      "164/164 [==============================] - 71s 434ms/step - loss: 2.0549 - val_loss: 2.0215\n",
      "Epoch 9/20\n",
      "164/164 [==============================] - 71s 435ms/step - loss: 1.9715 - val_loss: 1.9656\n",
      "Epoch 10/20\n",
      "164/164 [==============================] - 71s 435ms/step - loss: 1.8952 - val_loss: 1.9167\n",
      "Epoch 11/20\n",
      "164/164 [==============================] - 71s 436ms/step - loss: 1.8253 - val_loss: 1.8733\n",
      "Epoch 12/20\n",
      "164/164 [==============================] - 71s 434ms/step - loss: 1.7603 - val_loss: 1.8354\n",
      "Epoch 13/20\n",
      "164/164 [==============================] - 72s 438ms/step - loss: 1.6999 - val_loss: 1.8034\n",
      "Epoch 14/20\n",
      "164/164 [==============================] - 71s 435ms/step - loss: 1.6443 - val_loss: 1.7786\n",
      "Epoch 15/20\n",
      "164/164 [==============================] - 72s 436ms/step - loss: 1.5929 - val_loss: 1.7556\n",
      "Epoch 16/20\n",
      "164/164 [==============================] - 71s 431ms/step - loss: 1.5461 - val_loss: 1.7379\n",
      "Epoch 17/20\n",
      "164/164 [==============================] - 72s 436ms/step - loss: 1.5022 - val_loss: 1.7241\n",
      "Epoch 18/20\n",
      "164/164 [==============================] - 71s 431ms/step - loss: 1.4612 - val_loss: 1.7128\n",
      "Epoch 19/20\n",
      "164/164 [==============================] - 71s 433ms/step - loss: 1.4228 - val_loss: 1.7048\n",
      "Epoch 20/20\n",
      "164/164 [==============================] - 71s 434ms/step - loss: 1.3870 - val_loss: 1.6980\n",
      "Model: \"GRU_Encoder-Decoder_Scratch\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Encoder (Encoder)            multiple                  10773900  \n",
      "_________________________________________________________________\n",
      "Decoder (Decoder)            multiple                  8925900   \n",
      "_________________________________________________________________\n",
      "Dense (Dense)                multiple                  2964350   \n",
      "=================================================================\n",
      "Total params: 22,664,150\n",
      "Trainable params: 22,664,150\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_G1 = build_model_gru(embed='scratch', name='GRU_Encoder-Decoder_Scratch')\n",
    "train_model(model_G1, 'GRU_Encoder-Decoder_Scratch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NwkmIjG2OTzl"
   },
   "outputs": [],
   "source": [
    "model_G1.save_weights(model_path + '3_1_GRU_Scratch/' + '3_1_GRU_Scratch', save_format='tf') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hknHmo-vLXCd"
   },
   "source": [
    "### Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8R4MKg8NMBNy",
    "outputId": "426c48fa-a173-45f0-9a3e-b304d6a7becc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Text: At the party , the member has variety job .\n",
      "Output Text: At the party , the members have a variety of jobs .\n",
      "Predicted Text: At the school , we went to the library .\n",
      "====================================================================================================\n",
      "Input Text: Thank you NY .\n",
      "Output Text: Thank you , NY !\n",
      "Predicted Text: Thank you for your corrections .\n",
      "====================================================================================================\n",
      "Input Text: Few last days have been strange .\n",
      "Output Text: The last few days have been strange .\n",
      "Predicted Text: A few days was that my best .\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "predict_result(train, model_G1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6ODB4X8SMC65",
    "outputId": "9678db55-caa4-4f2f-f80c-3ea1d95ae7e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Text: Have you ever over the wall of school ?\n",
      "Output Text: Have you ever climbed over the wall at school ?\n",
      "Predicted Text: Have you ever seen in the U ?\n",
      "====================================================================================================\n",
      "Input Text: It is so narrow that I have to keep my body very fit everytime .\n",
      "Output Text: It is so narrow that I have to keep my body very fit all the time .\n",
      "Predicted Text: It was so so much , I must have to put it on the time .\n",
      "====================================================================================================\n",
      "Input Text: You can check the maintenance is finished or not at twitter .\n",
      "Output Text: You can check whether the maintenance is finished or not on twitter .\n",
      "Predicted Text: You can not use the computer or not the time I should not get up .\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "predict_result(test, model_G1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F52EwljL6ubI",
    "outputId": "0ca53889-b58b-4c7a-ed0f-88878b3784d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Avg. Train BLEU Score: 0.4440263747995784\n",
      "Avg. Test BLEU Score: 0.4109874622853129\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "get_BLEU(train, test, model_G1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qd4tTGXrLom2"
   },
   "source": [
    "## Encoder-Decoder: Glove Embed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7YoORuaVL5rd"
   },
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eVdf8gVE220P",
    "outputId": "ec464be3-7bcd-44c5-eb83-b634c99a5c12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "164/164 [==============================] - 50s 267ms/step - loss: 3.4469 - val_loss: 2.9999\n",
      "Epoch 2/20\n",
      "164/164 [==============================] - 42s 258ms/step - loss: 3.0403 - val_loss: 2.8814\n",
      "Epoch 3/20\n",
      "164/164 [==============================] - 42s 259ms/step - loss: 2.8895 - val_loss: 2.7156\n",
      "Epoch 4/20\n",
      "164/164 [==============================] - 42s 257ms/step - loss: 2.7301 - val_loss: 2.5811\n",
      "Epoch 5/20\n",
      "164/164 [==============================] - 42s 257ms/step - loss: 2.5923 - val_loss: 2.4503\n",
      "Epoch 6/20\n",
      "164/164 [==============================] - 42s 258ms/step - loss: 2.4532 - val_loss: 2.3196\n",
      "Epoch 7/20\n",
      "164/164 [==============================] - 42s 259ms/step - loss: 2.3145 - val_loss: 2.2015\n",
      "Epoch 8/20\n",
      "164/164 [==============================] - 43s 260ms/step - loss: 2.1995 - val_loss: 2.1091\n",
      "Epoch 9/20\n",
      "164/164 [==============================] - 42s 258ms/step - loss: 2.1063 - val_loss: 2.0357\n",
      "Epoch 10/20\n",
      "164/164 [==============================] - 43s 260ms/step - loss: 2.0269 - val_loss: 1.9729\n",
      "Epoch 11/20\n",
      "164/164 [==============================] - 42s 256ms/step - loss: 1.9569 - val_loss: 1.9201\n",
      "Epoch 12/20\n",
      "164/164 [==============================] - 43s 261ms/step - loss: 1.8953 - val_loss: 1.8736\n",
      "Epoch 13/20\n",
      "164/164 [==============================] - 42s 257ms/step - loss: 1.8408 - val_loss: 1.8343\n",
      "Epoch 14/20\n",
      "164/164 [==============================] - 42s 254ms/step - loss: 1.7929 - val_loss: 1.8001\n",
      "Epoch 15/20\n",
      "164/164 [==============================] - 43s 265ms/step - loss: 1.7504 - val_loss: 1.7713\n",
      "Epoch 16/20\n",
      "164/164 [==============================] - 43s 259ms/step - loss: 1.7120 - val_loss: 1.7462\n",
      "Epoch 17/20\n",
      "164/164 [==============================] - 42s 257ms/step - loss: 1.6773 - val_loss: 1.7236\n",
      "Epoch 18/20\n",
      "164/164 [==============================] - 42s 256ms/step - loss: 1.6459 - val_loss: 1.7046\n",
      "Epoch 19/20\n",
      "164/164 [==============================] - 43s 261ms/step - loss: 1.6167 - val_loss: 1.6884\n",
      "Epoch 20/20\n",
      "164/164 [==============================] - 42s 258ms/step - loss: 1.5902 - val_loss: 1.6733\n",
      "Model: \"GRU_Encoder-Decoder_Glove\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Encoder (Encoder)            multiple                  10773900  \n",
      "_________________________________________________________________\n",
      "Decoder (Decoder)            multiple                  8925900   \n",
      "_________________________________________________________________\n",
      "Dense (Dense)                multiple                  2964350   \n",
      "=================================================================\n",
      "Total params: 22,664,150\n",
      "Trainable params: 3,205,550\n",
      "Non-trainable params: 19,458,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_G2 = build_model_gru(embed='glove', name='GRU_Encoder-Decoder_Glove')\n",
    "train_model(model_G2, 'GRU_Encoder-Decoder_Glove')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H2YvwIzMOc9l"
   },
   "outputs": [],
   "source": [
    "model_G2.save_weights(model_path + '3_2_GRU_Glove/' + '3_2_GRU_Glove', save_format='tf') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5b9ZoJxIMROb"
   },
   "source": [
    "### Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GhqnHvnYMErZ",
    "outputId": "bedc1d06-e1bd-4558-f099-758768851020"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Text: At the party , the member has variety job .\n",
      "Output Text: At the party , the members have a variety of jobs .\n",
      "Predicted Text: In the party , a part of a party .\n",
      "====================================================================================================\n",
      "Input Text: Thank you NY .\n",
      "Output Text: Thank you , NY !\n",
      "Predicted Text: Thank you recommend .\n",
      "====================================================================================================\n",
      "Input Text: Few last days have been strange .\n",
      "Output Text: The last few days have been strange .\n",
      "Predicted Text: These days ago .\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "predict_result(train, model_G2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U5ifQRaKMGak",
    "outputId": "067d7706-b598-4fef-c8aa-a91edfd6150f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Text: Have you ever over the wall of school ?\n",
      "Output Text: Have you ever climbed over the wall at school ?\n",
      "Predicted Text: Have you have a different person in the school ?\n",
      "====================================================================================================\n",
      "Input Text: It is so narrow that I have to keep my body very fit everytime .\n",
      "Output Text: It is so narrow that I have to keep my body very fit all the time .\n",
      "Predicted Text: It is so so much that I have been so excited to my heart .\n",
      "====================================================================================================\n",
      "Input Text: You can check the maintenance is finished or not at twitter .\n",
      "Output Text: You can check whether the maintenance is finished or not on twitter .\n",
      "Predicted Text: I can check the computer or not check .\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "predict_result(test, model_G2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8s206mx_6veD",
    "outputId": "a33abd90-dcd7-41ec-fcc1-9c3238fd5e03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Avg. Train BLEU Score: 0.4585618940447448\n",
      "Avg. Test BLEU Score: 0.4324036178248305\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "get_BLEU(train, test, model_G2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sm_pjziGRG7P"
   },
   "source": [
    "## Encoder-Decoder: FastText Embed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZzCVkjF0RYrJ"
   },
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4UZIaMJZ26Zs",
    "outputId": "487e3a86-6e2d-46d4-a8af-81cda70bba98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "164/164 [==============================] - 50s 269ms/step - loss: 3.4796 - val_loss: 3.0083\n",
      "Epoch 2/20\n",
      "164/164 [==============================] - 42s 257ms/step - loss: 3.0666 - val_loss: 2.9242\n",
      "Epoch 3/20\n",
      "164/164 [==============================] - 43s 259ms/step - loss: 2.9304 - val_loss: 2.7505\n",
      "Epoch 4/20\n",
      "164/164 [==============================] - 41s 253ms/step - loss: 2.7589 - val_loss: 2.5945\n",
      "Epoch 5/20\n",
      "164/164 [==============================] - 42s 258ms/step - loss: 2.5971 - val_loss: 2.4453\n",
      "Epoch 6/20\n",
      "164/164 [==============================] - 42s 257ms/step - loss: 2.4529 - val_loss: 2.3250\n",
      "Epoch 7/20\n",
      "164/164 [==============================] - 41s 252ms/step - loss: 2.3365 - val_loss: 2.2279\n",
      "Epoch 8/20\n",
      "164/164 [==============================] - 42s 257ms/step - loss: 2.2389 - val_loss: 2.1474\n",
      "Epoch 9/20\n",
      "164/164 [==============================] - 42s 258ms/step - loss: 2.1541 - val_loss: 2.0764\n",
      "Epoch 10/20\n",
      "164/164 [==============================] - 42s 258ms/step - loss: 2.0784 - val_loss: 2.0144\n",
      "Epoch 11/20\n",
      "164/164 [==============================] - 42s 253ms/step - loss: 2.0125 - val_loss: 1.9631\n",
      "Epoch 12/20\n",
      "164/164 [==============================] - 42s 257ms/step - loss: 1.9548 - val_loss: 1.9199\n",
      "Epoch 13/20\n",
      "164/164 [==============================] - 42s 256ms/step - loss: 1.9038 - val_loss: 1.8784\n",
      "Epoch 14/20\n",
      "164/164 [==============================] - 41s 253ms/step - loss: 1.8570 - val_loss: 1.8441\n",
      "Epoch 15/20\n",
      "164/164 [==============================] - 42s 256ms/step - loss: 1.8140 - val_loss: 1.8118\n",
      "Epoch 16/20\n",
      "164/164 [==============================] - 42s 256ms/step - loss: 1.7748 - val_loss: 1.7837\n",
      "Epoch 17/20\n",
      "164/164 [==============================] - 42s 254ms/step - loss: 1.7387 - val_loss: 1.7581\n",
      "Epoch 18/20\n",
      "164/164 [==============================] - 42s 259ms/step - loss: 1.7057 - val_loss: 1.7352\n",
      "Epoch 19/20\n",
      "164/164 [==============================] - 42s 256ms/step - loss: 1.6748 - val_loss: 1.7151\n",
      "Epoch 20/20\n",
      "164/164 [==============================] - 42s 258ms/step - loss: 1.6459 - val_loss: 1.6958\n",
      "Model: \"GRU_Encoder-Decoder_Fast\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Encoder (Encoder)            multiple                  10773900  \n",
      "_________________________________________________________________\n",
      "Decoder (Decoder)            multiple                  8925900   \n",
      "_________________________________________________________________\n",
      "Dense (Dense)                multiple                  2964350   \n",
      "=================================================================\n",
      "Total params: 22,664,150\n",
      "Trainable params: 3,205,550\n",
      "Non-trainable params: 19,458,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_G3 = build_model_gru(embed='fast', name='GRU_Encoder-Decoder_Fast')\n",
    "train_model(model_G3, 'GRU_Encoder-Decoder_Fast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bw_cO1y9OkV1"
   },
   "outputs": [],
   "source": [
    "model_G3.save_weights(model_path + '3_3_GRU_Fast/' + '3_3_GRU_Fast', save_format='tf') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ic2RM8lESAm2"
   },
   "source": [
    "### Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3PToCrnYMIS7",
    "outputId": "96eb70f2-6302-46d7-86d3-d31014cb598b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Text: At the party , the member has variety job .\n",
      "Output Text: At the party , the members have a variety of jobs .\n",
      "Predicted Text: At first time , the company has a long time .\n",
      "====================================================================================================\n",
      "Input Text: Thank you NY .\n",
      "Output Text: Thank you , NY !\n",
      "Predicted Text: Thank you guys .\n",
      "====================================================================================================\n",
      "Input Text: Few last days have been strange .\n",
      "Output Text: The last few days have been strange .\n",
      "Predicted Text: The most years has been been a long .\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "predict_result(train, model_G3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rIQOUmroMJ29",
    "outputId": "ef19451a-dd33-438a-b5fb-7273298af36a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Text: Have you ever over the wall of school ?\n",
      "Output Text: Have you ever climbed over the wall at school ?\n",
      "Predicted Text: Have you ever seen in the company ?\n",
      "====================================================================================================\n",
      "Input Text: It is so narrow that I have to keep my body very fit everytime .\n",
      "Output Text: It is so narrow that I have to keep my body very fit all the time .\n",
      "Predicted Text: It is so I feel like my mind to do my best .\n",
      "====================================================================================================\n",
      "Input Text: You can check the maintenance is finished or not at twitter .\n",
      "Output Text: You can check whether the maintenance is finished or not on twitter .\n",
      "Predicted Text: You can not know the best time to get up .\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "predict_result(test, model_G3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OweEk0LL6wZn",
    "outputId": "e07d93fd-a90a-4248-c2e6-70be162a532d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Avg. Train BLEU Score: 0.4604231460584209\n",
      "Avg. Test BLEU Score: 0.4460802502826131\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "get_BLEU(train, test, model_G3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SNb6qnSU4ffj"
   },
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2BNF0_Mq4e1l",
    "outputId": "08fc8a30-82cf-48d8-c5c7-e7d22087fafa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------SUMMARY OF BASELINE MODEL--------------------------------------\n",
      "+-------------------------------+------------+----------+----------------------+---------------------+\n",
      "|             Model             | Train Loss | Val Loss | Avg Train BLEU Score | Avg Test BLEU Score |\n",
      "+-------------------------------+------------+----------+----------------------+---------------------+\n",
      "|   GRU Model - Scratch Embed   |    1.38    |   1.69   |         0.44         |         0.41        |\n",
      "|    GRU Model - Glove Embed    |    1.59    |   1.67   |         0.45         |         0.43        |\n",
      "|   GRU Model - Fasttext Embed  |    1.64    |   1.69   |         0.46         |         0.44        |\n",
      "|                               |            |          |                      |                     |\n",
      "|   LSTM Model - Scratch Embed  |    1.38    |   1.67   |         0.44         |         0.44        |\n",
      "|    LSTM Model - Glove Embed   |    1.63    |   1.68   |         0.44         |         0.43        |\n",
      "|  LSTM Model - Fasttext Embed  |    1.71    |   1.72   |         0.43         |         0.46        |\n",
      "|                               |            |          |                      |                     |\n",
      "|  BiLSTM Model - Scratch Embed |    1.18    |   1.54   |         0.43         |         0.42        |\n",
      "|   BiLSTM Model - Glove Embed  |    1.26    |   1.44   |         0.42         |         0.42        |\n",
      "| BiLSTM Model - Fasttext Embed |    1.38    |   1.46   |         0.42         |         0.41        |\n",
      "+-------------------------------+------------+----------+----------------------+---------------------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "  \n",
    "print('---------------------------------------SUMMARY OF BASELINE MODEL--------------------------------------')\n",
    "myTable = PrettyTable([\"Model\", \"Train Loss\", \"Val Loss\", \"Avg Train BLEU Score\", \"Avg Test BLEU Score\"])\n",
    "  \n",
    "myTable.add_row([\"GRU Model - Scratch Embed\", \"1.38\", \"1.69\", \"0.44\", \"0.41\"])\n",
    "myTable.add_row([\"GRU Model - Glove Embed\", \"1.59\", \"1.67\", \"0.45\", \"0.43\"])\n",
    "myTable.add_row([\"GRU Model - Fasttext Embed\", \"1.64\", \"1.69\", \"0.46\", \"0.44\"])\n",
    "myTable.add_row([\" \", \" \", \" \", \" \", \" \"])\n",
    "\n",
    "myTable.add_row([\"LSTM Model - Scratch Embed\", \"1.38\", \"1.67\", \"0.44\", \"0.44\"])\n",
    "myTable.add_row([\"LSTM Model - Glove Embed\", \"1.63\", \"1.68\", \"0.44\", \"0.43\"])\n",
    "myTable.add_row([\"LSTM Model - Fasttext Embed\", \"1.71\", \"1.72\", \"0.43\", \"0.46\"])\n",
    "myTable.add_row([\" \", \" \", \" \", \" \", \" \"])\n",
    "\n",
    "myTable.add_row([\"BiLSTM Model - Scratch Embed\", \"1.18\", \"1.54\", \"0.43\", \"0.42\"])\n",
    "myTable.add_row([\"BiLSTM Model - Glove Embed\", \"1.26\", \"1.44\", \"0.42\", \"0.42\"])\n",
    "myTable.add_row([\"BiLSTM Model - Fasttext Embed\", \"1.38\", \"1.46\", \"0.42\", \"0.41\"])\n",
    "\n",
    "print(myTable)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "3_2_Baseline_Model_(W).ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
